{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet_50 import ResNet50\n",
    "import torch\n",
    "from cifar_data import CifarDataset\n",
    "import torch.nn as nn\n",
    "from torch.nn.init import _calculate_fan_in_and_fan_out, _no_grad_uniform_\n",
    "import math\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_uniform_M(tensor, gain: float = 1., fac = 3.):\n",
    "    r\"\"\"Fills the input `Tensor` with values according to the method\n",
    "        described in `Understanding the difficulty of training deep feedforward\n",
    "        neural networks` - Glorot, X. & Bengio, Y. (2010), using a uniform\n",
    "        distribution. The resulting tensor will have values sampled from\n",
    "        :math:`\\mathcal{U}(-a, a)` where\n",
    "\n",
    "        .. math::\n",
    "            a = \\text{gain} \\times \\sqrt{\\frac{6}{\\text{fan\\_in} + \\text{fan\\_out}}}\n",
    "\n",
    "        Also known as Glorot initialization.\n",
    "\n",
    "        Args:\n",
    "            tensor: an n-dimensional `torch.Tensor`\n",
    "            gain: an optional scaling factor\n",
    "\n",
    "        Examples:\n",
    "            >>> w = torch.empty(3, 5)\n",
    "            >>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))\n",
    "        \"\"\"\n",
    "    fan_in, fan_out = _calculate_fan_in_and_fan_out(tensor)\n",
    "    std = gain * math.sqrt(2.0 / float(fan_in + fan_out))\n",
    "    a = math.sqrt(fac) * std  # Calculate uniform bounds from standard deviation\n",
    "\n",
    "    return _no_grad_uniform_(tensor, -a, a)\n",
    "\n",
    "def weights_init(m, method):\n",
    "    \"\"\"\n",
    "    Function for filters initialization\n",
    "    * function uses method from PyTorch to initialize weights\n",
    "    @ m - model\n",
    "    @ method - method to initialize weights\n",
    "    TODO: add custom method to initialize weights\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            if method == 'orthogonal':\n",
    "                torch.nn.init.orthogonal_(m.weight)  # type: ignore\n",
    "            elif method == 'xavier_uniform':\n",
    "                torch.nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
    "            elif method == 'xavier_uniform_M_2':\n",
    "                    self.xavier_uniform_M(m.weight, gain=1.0, fac=1.)\n",
    "            elif method == 'xavier_uniform_M_10':\n",
    "                self.xavier_uniform_M(m.weight, gain=1.0, fac=5.)\n",
    "            elif method == 'xavier_uniform_M_14':\n",
    "                self.xavier_uniform_M(m.weight, gain=1.0, fac=7.)\n",
    "            elif method == 'xavier_uniform_M_20':\n",
    "                self.xavier_uniform_M(m.weight, gain=1.0, fac=10.)\n",
    "            elif method == 'xavier_uniform_M_1':\n",
    "                self.xavier_uniform_M(m.weight, gain=1.0, fac=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(10)\n",
    "model.apply(lambda m: weights_init(m, \"xavier_uniform\"))\n",
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    model = model.cuda()\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001,  momentum=0.9)\n",
    "data = CifarDataset()\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test(dataset, model, criterion):\n",
    "    total = 0.\n",
    "    predicted = 0.\n",
    "    loss_t = 0\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataset.testloader:\n",
    "            labels = labels.cuda()\n",
    "            data = data.cuda()\n",
    "            out = model(data)\n",
    "            output = torch.argmax(out, dim=1)\n",
    "            \n",
    "            total += labels.shape[0]\n",
    "            predicted += torch.sum(output == labels).cpu().item()\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "            loss_t += loss.cpu().item()\n",
    "            \n",
    "\n",
    "    return predicted/total*100  # type:ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [1, 100](epoch, minibatch):  2.1888458633422854\n",
      "Loss [1, 200](epoch, minibatch):  2.0208187007904055\n",
      "Loss [1, 300](epoch, minibatch):  1.9455267333984374\n",
      "Loss [1, 400](epoch, minibatch):  1.9043874430656433\n",
      "acc: 11.28 %\n",
      "Loss [2, 100](epoch, minibatch):  1.8088793027400971\n",
      "Loss [2, 200](epoch, minibatch):  1.7577320384979247\n",
      "Loss [2, 300](epoch, minibatch):  1.7103248071670532\n",
      "Loss [2, 400](epoch, minibatch):  1.7024067270755767\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for i, inp in enumerate(data.trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "    acc = test(data, model, criterion)\n",
    "    print(\"acc: {:.2f} %\".format(acc))\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "\n",
    "print('Training Done')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
