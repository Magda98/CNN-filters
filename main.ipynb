{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from CifarDataset import CifarDataset\n",
    "from IntelDataset import IntelDataset\n",
    "from TrainModel import TrainModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image size in px (square image)\n",
    "input_size = 32\n",
    "dataset_name = \"cifar\"\n",
    "epoch = 6\n",
    "0\n",
    "\n",
    "# methods = [\"xavier_uniform\",'xavier_uniform_M_10', 'xavier_uniform_M_2', 'xavier_uniform_M_1', 'xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "methods = ['xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "for method in methods:\n",
    "    for apt in range(3):\n",
    "        model = TrainModel(dataset=CifarDataset(), method=method, input_size=input_size,\n",
    "                                c_kernels=[5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + dataset_name + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + dataset_name + method + \"_\" + str(apt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 49.97 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.1027\n",
      "pk: 55.87 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.0893\n",
      "pk: 58.70 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 0.9553\n",
      "pk: 61.87 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 0.8813\n",
      "pk: 61.43 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 0.9369\n",
      "pk: 65.50 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.8690\n",
      "pk: 67.73 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.7833\n",
      "pk: 69.20 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.8087\n",
      "pk: 68.53 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.0457\n",
      "pk: 67.97 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.9605\n",
      "pk: 70.83 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 10............. Loss: 0.9172\n",
      "pk: 70.63 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 11............. Loss: 0.7741\n",
      "pk: 72.60 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 12............. Loss: 0.7049\n",
      "pk: 70.63 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 13............. Loss: 1.1456\n",
      "pk: 71.40 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 14............. Loss: 0.9630\n",
      "pk: 71.37 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 15............. Loss: 0.9133\n",
      "pk: 69.47 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 16............. Loss: 0.8846\n",
      "pk: 72.23 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 17............. Loss: 0.9156\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 18............. Loss: 0.9681\n",
      "pk: 69.93 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 19............. Loss: 0.9905\n",
      "pk: 69.47 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 20............. Loss: 0.8566\n",
      "pk: 73.40 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 21............. Loss: 0.9052\n",
      "pk: 73.57 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 22............. Loss: 0.8174\n",
      "pk: 67.93 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 23............. Loss: 0.5993\n",
      "pk: 72.93 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 24............. Loss: 0.5922\n",
      "pk: 72.60 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 25............. Loss: 0.8672\n",
      "pk: 71.57 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 26............. Loss: 0.7461\n",
      "pk: 71.30 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 27............. Loss: 0.7053\n",
      "pk: 70.63 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 28............. Loss: 1.0872\n",
      "pk: 72.47 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 29............. Loss: 0.9221\n",
      "pk: 69.57 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 30............. Loss: 1.0317\n",
      "pk: 73.50 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 31............. Loss: 1.0094\n",
      "pk: 72.37 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 32............. Loss: 0.4982\n",
      "pk: 71.30 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 33............. Loss: 1.0391\n",
      "pk: 71.43 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 34............. Loss: 0.6342\n",
      "pk: 71.53 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 35............. Loss: 0.9799\n",
      "pk: 68.03 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 36............. Loss: 0.9869\n",
      "pk: 71.57 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 37............. Loss: 0.7816\n",
      "pk: 65.83 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 38............. Loss: 1.0788\n",
      "pk: 68.57 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 39............. Loss: 0.8321\n",
      "pk: 66.17 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 40............. Loss: 0.7422\n",
      "pk: 54.73 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 41............. Loss: 0.8708\n",
      "pk: 69.13 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 42............. Loss: 1.1546\n",
      "pk: 67.33 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 43............. Loss: 0.7893\n",
      "pk: 64.83 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 44............. Loss: 0.9901\n",
      "pk: 66.93 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 45............. Loss: 0.6280\n",
      "pk: 66.40 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 46............. Loss: 1.1392\n",
      "pk: 63.53 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 47............. Loss: 0.8550\n",
      "pk: 66.77 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 48............. Loss: 0.7939\n",
      "pk: 67.07 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 49............. Loss: 1.0859\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 54.63 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.2913\n",
      "pk: 57.63 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.0121\n",
      "pk: 60.80 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 0.9193\n",
      "pk: 61.20 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.1620\n",
      "pk: 63.73 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 0.7977\n",
      "pk: 65.57 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.8661\n",
      "pk: 67.07 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.9850\n",
      "pk: 69.10 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 1.0215\n",
      "pk: 69.77 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.8749\n",
      "pk: 72.13 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.8432\n",
      "pk: 70.90 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.6290\n",
      "pk: 71.93 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.7509\n",
      "pk: 75.47 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.6312\n",
      "pk: 73.60 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.7908\n",
      "pk: 74.80 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 0.6001\n",
      "pk: 75.23 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.8018\n",
      "pk: 76.20 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.7325\n",
      "pk: 69.73 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 17............. Loss: 0.9068\n",
      "pk: 76.70 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 18............. Loss: 0.6353\n",
      "pk: 76.60 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 19............. Loss: 0.7558\n",
      "pk: 76.40 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 20............. Loss: 0.6846\n",
      "pk: 77.80 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 21............. Loss: 0.5817\n",
      "pk: 58.73 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 22............. Loss: 0.7381\n",
      "pk: 76.27 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 23............. Loss: 1.2762\n",
      "pk: 75.67 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 24............. Loss: 0.4481\n",
      "pk: 78.13 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 25............. Loss: 0.7504\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 26............. Loss: 0.5869\n",
      "pk: 76.53 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 27............. Loss: 0.9865\n",
      "pk: 75.30 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 28............. Loss: 0.6291\n",
      "pk: 71.83 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 29............. Loss: 0.7974\n",
      "pk: 68.73 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 30............. Loss: 0.6335\n",
      "pk: 75.27 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 31............. Loss: 0.9980\n",
      "pk: 68.43 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 32............. Loss: 0.9863\n",
      "pk: 76.23 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 33............. Loss: 0.7446\n",
      "pk: 73.30 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 34............. Loss: 1.0700\n",
      "pk: 72.17 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 35............. Loss: 0.6757\n",
      "pk: 64.13 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 36............. Loss: 1.2116\n",
      "pk: 74.03 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 37............. Loss: 0.9746\n",
      "pk: 73.80 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 38............. Loss: 0.9996\n",
      "pk: 71.83 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 39............. Loss: 0.6197\n",
      "pk: 71.87 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 40............. Loss: 0.5126\n",
      "pk: 71.00 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 41............. Loss: 0.7354\n",
      "pk: 74.87 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 42............. Loss: 0.7678\n",
      "pk: 63.63 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 43............. Loss: 1.0885\n",
      "pk: 59.97 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 44............. Loss: 1.0368\n",
      "pk: 71.27 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 45............. Loss: 0.8534\n",
      "pk: 54.67 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 46............. Loss: 1.0812\n",
      "pk: 66.73 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 47............. Loss: 1.6166\n",
      "pk: 63.70 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 48............. Loss: 0.6522\n",
      "pk: 63.93 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 49............. Loss: 1.2677\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 53.00 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.5205\n",
      "pk: 56.30 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.1595\n",
      "pk: 58.67 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.1081\n",
      "pk: 61.07 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.1971\n",
      "pk: 65.37 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 0.8836\n",
      "pk: 61.87 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.9467\n",
      "pk: 68.27 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.8695\n",
      "pk: 66.87 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.8698\n",
      "pk: 67.77 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.9127\n",
      "pk: 69.50 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.9174\n",
      "pk: 71.53 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 10............. Loss: 0.6744\n",
      "pk: 70.57 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 11............. Loss: 0.9019\n",
      "pk: 69.77 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 12............. Loss: 0.7743\n",
      "pk: 73.93 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 13............. Loss: 0.8597\n",
      "pk: 75.40 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 14............. Loss: 0.7673\n",
      "pk: 74.53 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 15............. Loss: 0.5025\n",
      "pk: 74.27 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 16............. Loss: 0.5117\n",
      "pk: 77.10 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 17............. Loss: 0.5924\n",
      "pk: 73.33 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 18............. Loss: 0.7899\n",
      "pk: 76.70 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 19............. Loss: 0.9175\n",
      "pk: 73.07 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 20............. Loss: 0.6333\n",
      "pk: 68.73 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 21............. Loss: 0.7789\n",
      "pk: 74.23 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 22............. Loss: 0.8718\n",
      "pk: 74.47 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 23............. Loss: 0.7898\n",
      "pk: 73.23 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 24............. Loss: 0.5439\n",
      "pk: 74.60 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 25............. Loss: 0.6904\n",
      "pk: 76.30 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 26............. Loss: 0.5185\n",
      "pk: 77.73 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 27............. Loss: 0.5269\n",
      "pk: 73.10 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 28............. Loss: 0.5622\n",
      "pk: 71.60 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 29............. Loss: 0.8697\n",
      "pk: 73.33 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 30............. Loss: 0.5367\n",
      "pk: 69.73 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 31............. Loss: 0.6934\n",
      "pk: 76.90 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 32............. Loss: 0.8936\n",
      "pk: 73.77 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 33............. Loss: 0.3712\n",
      "pk: 75.73 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 34............. Loss: 0.6342\n",
      "pk: 70.30 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 35............. Loss: 0.5625\n",
      "pk: 69.60 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 36............. Loss: 0.9507\n",
      "pk: 73.07 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 37............. Loss: 0.6828\n",
      "pk: 73.07 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 38............. Loss: 0.7045\n",
      "pk: 70.90 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 39............. Loss: 0.7818\n",
      "pk: 71.90 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 40............. Loss: 0.8108\n",
      "pk: 68.23 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 41............. Loss: 0.9900\n",
      "pk: 70.90 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 42............. Loss: 1.0356\n",
      "pk: 71.00 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 43............. Loss: 0.6116\n",
      "pk: 68.17 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 44............. Loss: 1.5815\n",
      "pk: 71.97 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 45............. Loss: 0.9059\n",
      "pk: 64.93 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 46............. Loss: 0.4753\n",
      "pk: 68.60 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 47............. Loss: 0.6379\n",
      "pk: 64.13 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 48............. Loss: 1.1549\n",
      "pk: 68.47 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 49............. Loss: 1.0532\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 53.43 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.3746\n",
      "pk: 58.00 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.4060\n",
      "pk: 57.67 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.3027\n",
      "pk: 61.17 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.0573\n",
      "pk: 65.03 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 0.8455\n",
      "pk: 65.47 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.9615\n",
      "pk: 69.17 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.7505\n",
      "pk: 67.10 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.6227\n",
      "pk: 69.27 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.1417\n",
      "pk: 70.93 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.6361\n",
      "pk: 70.77 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.9255\n",
      "pk: 71.80 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.6938\n",
      "pk: 73.73 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.5269\n",
      "pk: 72.33 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.6227\n",
      "pk: 74.20 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 14............. Loss: 0.9244\n",
      "pk: 75.37 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 15............. Loss: 0.6588\n",
      "pk: 72.50 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 16............. Loss: 1.1085\n",
      "pk: 74.70 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 17............. Loss: 0.6437\n",
      "pk: 71.30 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 18............. Loss: 1.0346\n",
      "pk: 74.43 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 19............. Loss: 0.8617\n",
      "pk: 73.20 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 20............. Loss: 0.6444\n",
      "pk: 76.10 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 21............. Loss: 0.7547\n",
      "pk: 72.23 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 22............. Loss: 0.6680\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 23............. Loss: 0.4276\n",
      "pk: 74.50 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 24............. Loss: 0.8011\n",
      "pk: 74.43 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 25............. Loss: 0.6033\n",
      "pk: 76.63 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 26............. Loss: 0.4757\n",
      "pk: 72.70 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 27............. Loss: 1.0393\n",
      "pk: 65.27 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 28............. Loss: 0.9136\n",
      "pk: 64.00 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 29............. Loss: 0.7677\n",
      "pk: 68.87 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 30............. Loss: 1.2617\n",
      "pk: 73.60 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 31............. Loss: 0.5581\n",
      "pk: 73.43 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 32............. Loss: 0.6859\n",
      "pk: 70.13 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 33............. Loss: 0.7508\n",
      "pk: 71.67 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 34............. Loss: 0.5666\n",
      "pk: 73.03 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 35............. Loss: 0.9058\n",
      "pk: 66.83 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 36............. Loss: 0.8963\n",
      "pk: 65.97 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 37............. Loss: 0.6833\n",
      "pk: 69.47 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 38............. Loss: 0.9406\n",
      "pk: 68.77 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 39............. Loss: 1.0320\n",
      "pk: 68.03 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 40............. Loss: 1.0580\n",
      "pk: 68.53 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 41............. Loss: 0.9064\n",
      "pk: 66.77 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 42............. Loss: 1.0523\n",
      "pk: 67.47 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 43............. Loss: 0.7093\n",
      "pk: 59.10 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 44............. Loss: 1.0786\n",
      "pk: 65.33 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 45............. Loss: 1.2745\n",
      "pk: 67.17 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 46............. Loss: 1.0113\n",
      "pk: 65.90 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 47............. Loss: 1.5514\n",
      "pk: 65.83 %\n",
      "Learning rate: 0.0035080587\n",
      "Epoch: 48............. Loss: 1.1170\n",
      "pk: 63.13 %\n",
      "Learning rate: 0.0035080587\n",
      "Epoch: 49............. Loss: 0.9144\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 28.73 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.4800\n",
      "pk: 57.33 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.2509\n",
      "pk: 59.73 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 0.9622\n",
      "pk: 59.60 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.1729\n",
      "pk: 57.97 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.1446\n",
      "pk: 62.27 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.8838\n",
      "pk: 65.90 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.8503\n",
      "pk: 64.90 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.8314\n",
      "pk: 67.87 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.9432\n",
      "pk: 66.03 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.9295\n",
      "pk: 68.70 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.8142\n",
      "pk: 71.73 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.7884\n",
      "pk: 70.03 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.8407\n",
      "pk: 70.30 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.7725\n",
      "pk: 68.73 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 0.8429\n",
      "pk: 68.63 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 15............. Loss: 0.7789\n",
      "pk: 74.43 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 16............. Loss: 0.7762\n",
      "pk: 74.83 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 17............. Loss: 0.6978\n",
      "pk: 72.67 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 18............. Loss: 0.6281\n",
      "pk: 70.30 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 19............. Loss: 0.6956\n",
      "pk: 65.93 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 20............. Loss: 0.6404\n",
      "pk: 75.43 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 21............. Loss: 0.7060\n",
      "pk: 62.33 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 22............. Loss: 0.9754\n",
      "pk: 67.60 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 23............. Loss: 0.7913\n",
      "pk: 72.73 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 24............. Loss: 0.6396\n",
      "pk: 73.43 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 25............. Loss: 0.8722\n",
      "pk: 70.77 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 26............. Loss: 1.0321\n",
      "pk: 73.27 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 27............. Loss: 0.8869\n",
      "pk: 70.73 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 28............. Loss: 0.5317\n",
      "pk: 71.63 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 29............. Loss: 0.7817\n",
      "pk: 72.43 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 30............. Loss: 0.5517\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 31............. Loss: 0.6239\n",
      "pk: 72.30 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 32............. Loss: 0.6468\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 33............. Loss: 0.7739\n",
      "pk: 71.93 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 34............. Loss: 0.6301\n",
      "pk: 71.13 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 35............. Loss: 0.8231\n",
      "pk: 72.43 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 36............. Loss: 0.8970\n",
      "pk: 72.87 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 37............. Loss: 0.6591\n",
      "pk: 71.30 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 38............. Loss: 0.6945\n",
      "pk: 72.33 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 39............. Loss: 0.9320\n",
      "pk: 66.87 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 40............. Loss: 0.9496\n",
      "pk: 71.63 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 41............. Loss: 0.9039\n",
      "pk: 71.63 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 42............. Loss: 0.7200\n",
      "pk: 69.90 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 43............. Loss: 0.5343\n",
      "pk: 73.13 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 44............. Loss: 0.8200\n",
      "pk: 71.80 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 45............. Loss: 0.7330\n",
      "pk: 63.33 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 46............. Loss: 0.9149\n",
      "pk: 72.67 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 47............. Loss: 0.6694\n",
      "pk: 67.87 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 48............. Loss: 0.8062\n",
      "pk: 58.53 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 49............. Loss: 0.7971\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 48.27 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.3612\n",
      "pk: 58.93 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.0337\n",
      "pk: 60.73 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.2811\n",
      "pk: 62.13 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.0895\n",
      "pk: 68.20 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 0.9682\n",
      "pk: 68.90 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.8860\n",
      "pk: 67.43 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.9144\n",
      "pk: 69.50 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.6132\n",
      "pk: 72.10 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.9716\n",
      "pk: 73.47 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.6348\n",
      "pk: 75.77 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.6593\n",
      "pk: 76.07 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.5731\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 12............. Loss: 0.7406\n",
      "pk: 73.03 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 13............. Loss: 0.6904\n",
      "pk: 77.40 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 14............. Loss: 0.5763\n",
      "pk: 77.47 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 15............. Loss: 0.6451\n",
      "pk: 76.93 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 16............. Loss: 0.8264\n",
      "pk: 76.57 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 17............. Loss: 0.5570\n",
      "pk: 77.93 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 18............. Loss: 0.4996\n",
      "pk: 77.30 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 19............. Loss: 0.5947\n",
      "pk: 79.77 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 20............. Loss: 0.4718\n",
      "pk: 78.67 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 21............. Loss: 0.5096\n",
      "pk: 75.70 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 22............. Loss: 0.5462\n",
      "pk: 78.17 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 23............. Loss: 0.6085\n",
      "pk: 76.60 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 24............. Loss: 0.3461\n",
      "pk: 77.23 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 25............. Loss: 0.8640\n",
      "pk: 69.37 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 26............. Loss: 0.6609\n",
      "pk: 77.13 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 27............. Loss: 0.7365\n",
      "pk: 77.43 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 28............. Loss: 0.8084\n",
      "pk: 75.83 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 29............. Loss: 0.8217\n",
      "pk: 73.53 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 30............. Loss: 1.0388\n",
      "pk: 71.23 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 31............. Loss: 0.7586\n",
      "pk: 74.60 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 32............. Loss: 0.7583\n",
      "pk: 74.40 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 33............. Loss: 0.6908\n",
      "pk: 74.27 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 34............. Loss: 0.4832\n",
      "pk: 79.07 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 35............. Loss: 0.6502\n",
      "pk: 75.67 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 36............. Loss: 0.5380\n",
      "pk: 60.03 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 37............. Loss: 1.0635\n",
      "pk: 66.30 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 38............. Loss: 1.2559\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 39............. Loss: 0.9469\n",
      "pk: 73.83 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 40............. Loss: 1.0236\n",
      "pk: 74.53 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 41............. Loss: 0.5876\n",
      "pk: 72.37 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 42............. Loss: 0.9400\n",
      "pk: 74.27 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 43............. Loss: 0.5914\n",
      "pk: 73.00 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 44............. Loss: 0.3882\n",
      "pk: 62.57 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 45............. Loss: 0.9212\n",
      "pk: 69.07 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 46............. Loss: 1.1766\n",
      "pk: 68.87 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 47............. Loss: 1.0045\n",
      "pk: 68.67 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 48............. Loss: 0.7696\n",
      "pk: 67.43 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 49............. Loss: 0.6722\n"
     ]
    }
   ],
   "source": [
    "input_size = 150\n",
    "epoch = 50\n",
    "dataset_name = \"intel\"\n",
    "methods = ['xavier_uniform_M_2', 'xavier_uniform_M_1',]\n",
    "\n",
    "for method in methods:\n",
    "    for apt in range(3, 6):\n",
    "        model = TrainModel(dataset=IntelDataset(), method=method, input_size=input_size,\n",
    "                            c_kernels=[7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + method + \"_\" + str(apt))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
