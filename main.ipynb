{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from CifarDataset import CifarDataset\n",
    "from IntelDataset import IntelDataset\n",
    "from TrainModel import TrainModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image size in px (square image)\n",
    "input_size = 32\n",
    "dataset_name = \"cifar\"\n",
    "epoch = 6\n",
    "0\n",
    "\n",
    "# methods = [\"xavier_uniform\",'xavier_uniform_M_10', 'xavier_uniform_M_2', 'xavier_uniform_M_1', 'xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "methods = ['xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "for method in methods:\n",
    "    for apt in range(3):\n",
    "        model = TrainModel(dataset=CifarDataset(), method=method, input_size=input_size,\n",
    "                                c_kernels=[5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + dataset_name + method + \"_\" + str(apt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.8071\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.8227\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 1.7958\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.7886\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 1.7892\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 1.7806\n",
      "pk: 22.80 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 1.7897\n",
      "pk: 27.80 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 1.7526\n",
      "pk: 34.80 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 1.5432\n",
      "pk: 37.87 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 1.7335\n",
      "pk: 38.13 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 1.5711\n",
      "pk: 38.83 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 1.5196\n",
      "pk: 40.53 %\n",
      "Learning rate: 0.0001601032\n",
      "Epoch: 12............. Loss: 1.4184\n",
      "pk: 42.00 %\n",
      "Learning rate: 0.0001665074\n",
      "Epoch: 13............. Loss: 1.5136\n",
      "pk: 43.33 %\n",
      "Learning rate: 0.0001731676\n",
      "Epoch: 14............. Loss: 1.2230\n",
      "pk: 49.10 %\n",
      "Learning rate: 0.0001800944\n",
      "Epoch: 15............. Loss: 1.2443\n",
      "pk: 54.10 %\n",
      "Learning rate: 0.0001872981\n",
      "Epoch: 16............. Loss: 1.1231\n",
      "pk: 58.63 %\n",
      "Learning rate: 0.0001947900\n",
      "Epoch: 17............. Loss: 1.2119\n",
      "pk: 50.47 %\n",
      "Learning rate: 0.0002025817\n",
      "Epoch: 18............. Loss: 1.0270\n",
      "pk: 60.20 %\n",
      "Learning rate: 0.0002106849\n",
      "Epoch: 19............. Loss: 0.9723\n",
      "pk: 62.73 %\n",
      "Learning rate: 0.0002191123\n",
      "Epoch: 20............. Loss: 1.0035\n",
      "pk: 64.50 %\n",
      "Learning rate: 0.0002278768\n",
      "Epoch: 21............. Loss: 0.7852\n",
      "pk: 62.73 %\n",
      "Learning rate: 0.0002369919\n",
      "Epoch: 22............. Loss: 1.5003\n",
      "pk: 69.17 %\n",
      "Learning rate: 0.0002464716\n",
      "Epoch: 23............. Loss: 0.8969\n",
      "pk: 67.07 %\n",
      "Learning rate: 0.0002563304\n",
      "Epoch: 24............. Loss: 0.7756\n",
      "pk: 72.13 %\n",
      "Learning rate: 0.0002665836\n",
      "Epoch: 25............. Loss: 0.8278\n",
      "pk: 72.50 %\n",
      "Learning rate: 0.0002772470\n",
      "Epoch: 26............. Loss: 0.7224\n",
      "pk: 73.67 %\n",
      "Learning rate: 0.0002883369\n",
      "Epoch: 27............. Loss: 0.8402\n",
      "pk: 74.07 %\n",
      "Learning rate: 0.0002998703\n",
      "Epoch: 28............. Loss: 0.6304\n",
      "pk: 74.90 %\n",
      "Learning rate: 0.0003118651\n",
      "Epoch: 29............. Loss: 0.5702\n",
      "pk: 75.90 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 30............. Loss: 0.7380\n",
      "pk: 77.27 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 31............. Loss: 0.3971\n",
      "pk: 78.17 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 32............. Loss: 0.6470\n",
      "pk: 79.60 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 33............. Loss: 0.5847\n",
      "pk: 79.90 %\n",
      "Learning rate: 0.0003794316\n",
      "Epoch: 34............. Loss: 0.4346\n",
      "pk: 78.70 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 35............. Loss: 0.5664\n",
      "pk: 80.03 %\n",
      "Learning rate: 0.0004103933\n",
      "Epoch: 36............. Loss: 0.6894\n",
      "pk: 81.77 %\n",
      "Learning rate: 0.0004268090\n",
      "Epoch: 37............. Loss: 0.5426\n",
      "pk: 80.53 %\n",
      "Learning rate: 0.0004438813\n",
      "Epoch: 38............. Loss: 0.4500\n",
      "pk: 82.90 %\n",
      "Learning rate: 0.0004616366\n",
      "Epoch: 39............. Loss: 0.2102\n",
      "pk: 83.53 %\n",
      "Learning rate: 0.0004801021\n",
      "Epoch: 40............. Loss: 0.5204\n",
      "pk: 83.23 %\n",
      "Learning rate: 0.0004993061\n",
      "Epoch: 41............. Loss: 0.8047\n",
      "pk: 83.73 %\n",
      "Learning rate: 0.0005192784\n",
      "Epoch: 42............. Loss: 0.5205\n",
      "pk: 85.13 %\n",
      "Learning rate: 0.0005400495\n",
      "Epoch: 43............. Loss: 0.3760\n",
      "pk: 81.47 %\n",
      "Learning rate: 0.0005616515\n",
      "Epoch: 44............. Loss: 0.5142\n",
      "pk: 82.77 %\n",
      "Learning rate: 0.0005841176\n",
      "Epoch: 45............. Loss: 0.4904\n",
      "pk: 85.60 %\n",
      "Learning rate: 0.0006074823\n",
      "Epoch: 46............. Loss: 0.4166\n",
      "pk: 86.23 %\n",
      "Learning rate: 0.0006317816\n",
      "Epoch: 47............. Loss: 0.4635\n",
      "pk: 85.23 %\n",
      "Learning rate: 0.0006570528\n",
      "Epoch: 48............. Loss: 0.3846\n",
      "pk: 85.20 %\n",
      "Learning rate: 0.0006833349\n",
      "Epoch: 49............. Loss: 0.2790\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 17.00 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.7987\n",
      "pk: 17.00 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.8224\n",
      "pk: 17.00 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 1.7823\n",
      "pk: 19.60 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.7782\n",
      "pk: 29.87 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 1.7833\n",
      "pk: 29.27 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 1.8126\n",
      "pk: 28.67 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 1.7592\n",
      "pk: 29.07 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 1.7765\n",
      "pk: 32.47 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 1.6390\n",
      "pk: 29.63 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 1.6432\n",
      "pk: 31.27 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 1.6361\n",
      "pk: 32.10 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 1.6353\n",
      "pk: 34.00 %\n",
      "Learning rate: 0.0001601032\n",
      "Epoch: 12............. Loss: 1.4058\n",
      "pk: 35.90 %\n",
      "Learning rate: 0.0001665074\n",
      "Epoch: 13............. Loss: 1.5383\n",
      "pk: 37.07 %\n",
      "Learning rate: 0.0001731676\n",
      "Epoch: 14............. Loss: 1.3570\n",
      "pk: 39.43 %\n",
      "Learning rate: 0.0001800944\n",
      "Epoch: 15............. Loss: 1.3072\n",
      "pk: 39.83 %\n",
      "Learning rate: 0.0001872981\n",
      "Epoch: 16............. Loss: 1.2332\n",
      "pk: 49.03 %\n",
      "Learning rate: 0.0001947900\n",
      "Epoch: 17............. Loss: 1.3126\n",
      "pk: 55.07 %\n",
      "Learning rate: 0.0002025817\n",
      "Epoch: 18............. Loss: 1.0680\n",
      "pk: 57.67 %\n",
      "Learning rate: 0.0002106849\n",
      "Epoch: 19............. Loss: 0.9303\n",
      "pk: 59.47 %\n",
      "Learning rate: 0.0002191123\n",
      "Epoch: 20............. Loss: 0.9505\n",
      "pk: 59.63 %\n",
      "Learning rate: 0.0002278768\n",
      "Epoch: 21............. Loss: 0.9909\n",
      "pk: 62.50 %\n",
      "Learning rate: 0.0002369919\n",
      "Epoch: 22............. Loss: 0.8682\n",
      "pk: 64.23 %\n",
      "Learning rate: 0.0002464716\n",
      "Epoch: 23............. Loss: 0.8342\n",
      "pk: 64.37 %\n",
      "Learning rate: 0.0002563304\n",
      "Epoch: 24............. Loss: 0.9809\n",
      "pk: 67.13 %\n",
      "Learning rate: 0.0002665836\n",
      "Epoch: 25............. Loss: 0.9238\n",
      "pk: 68.53 %\n",
      "Learning rate: 0.0002772470\n",
      "Epoch: 26............. Loss: 0.7506\n",
      "pk: 71.87 %\n",
      "Learning rate: 0.0002883369\n",
      "Epoch: 27............. Loss: 0.7469\n",
      "pk: 73.93 %\n",
      "Learning rate: 0.0002998703\n",
      "Epoch: 28............. Loss: 0.4637\n",
      "pk: 75.93 %\n",
      "Learning rate: 0.0003118651\n",
      "Epoch: 29............. Loss: 0.7001\n",
      "pk: 76.00 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 30............. Loss: 0.4735\n",
      "pk: 78.40 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 31............. Loss: 0.3909\n",
      "pk: 78.77 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 32............. Loss: 0.5362\n",
      "pk: 79.73 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 33............. Loss: 0.5745\n",
      "pk: 80.63 %\n",
      "Learning rate: 0.0003794316\n",
      "Epoch: 34............. Loss: 0.6347\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 35............. Loss: 0.4206\n",
      "pk: 81.63 %\n",
      "Learning rate: 0.0004103933\n",
      "Epoch: 36............. Loss: 0.5618\n",
      "pk: 82.07 %\n",
      "Learning rate: 0.0004268090\n",
      "Epoch: 37............. Loss: 0.6005\n",
      "pk: 81.60 %\n",
      "Learning rate: 0.0004438813\n",
      "Epoch: 38............. Loss: 0.6248\n",
      "pk: 82.97 %\n",
      "Learning rate: 0.0004616366\n",
      "Epoch: 39............. Loss: 0.3652\n",
      "pk: 82.00 %\n",
      "Learning rate: 0.0004801021\n",
      "Epoch: 40............. Loss: 0.3714\n",
      "pk: 83.77 %\n",
      "Learning rate: 0.0004993061\n",
      "Epoch: 41............. Loss: 0.5882\n",
      "pk: 84.03 %\n",
      "Learning rate: 0.0005192784\n",
      "Epoch: 42............. Loss: 0.6154\n",
      "pk: 84.33 %\n",
      "Learning rate: 0.0005400495\n",
      "Epoch: 43............. Loss: 0.5089\n",
      "pk: 83.40 %\n",
      "Learning rate: 0.0005616515\n",
      "Epoch: 44............. Loss: 0.5979\n",
      "pk: 83.67 %\n",
      "Learning rate: 0.0005616515\n",
      "Epoch: 45............. Loss: 0.3131\n",
      "pk: 85.40 %\n",
      "Learning rate: 0.0005841176\n",
      "Epoch: 46............. Loss: 0.3803\n",
      "pk: 84.77 %\n",
      "Learning rate: 0.0005841176\n",
      "Epoch: 47............. Loss: 0.1931\n",
      "pk: 84.13 %\n",
      "Learning rate: 0.0006074823\n",
      "Epoch: 48............. Loss: 0.3649\n",
      "pk: 85.93 %\n",
      "Learning rate: 0.0006317816\n",
      "Epoch: 49............. Loss: 0.4016\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.8308\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.7675\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 1.7446\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.7808\n",
      "pk: 15.80 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 1.7778\n",
      "pk: 28.53 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 1.7560\n",
      "pk: 32.60 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 1.7662\n",
      "pk: 35.67 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 1.6461\n",
      "pk: 37.50 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 1.6371\n",
      "pk: 40.70 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 1.4797\n",
      "pk: 45.77 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 1.4101\n",
      "pk: 48.33 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 1.3931\n",
      "pk: 50.30 %\n",
      "Learning rate: 0.0001601032\n",
      "Epoch: 12............. Loss: 1.3349\n",
      "pk: 51.13 %\n",
      "Learning rate: 0.0001665074\n",
      "Epoch: 13............. Loss: 1.0396\n",
      "pk: 55.87 %\n",
      "Learning rate: 0.0001731676\n",
      "Epoch: 14............. Loss: 1.0230\n",
      "pk: 56.30 %\n",
      "Learning rate: 0.0001800944\n",
      "Epoch: 15............. Loss: 0.8658\n",
      "pk: 59.43 %\n",
      "Learning rate: 0.0001872981\n",
      "Epoch: 16............. Loss: 0.8813\n",
      "pk: 62.00 %\n",
      "Learning rate: 0.0001947900\n",
      "Epoch: 17............. Loss: 1.2423\n",
      "pk: 61.20 %\n",
      "Learning rate: 0.0002025817\n",
      "Epoch: 18............. Loss: 1.0648\n",
      "pk: 64.63 %\n",
      "Learning rate: 0.0002106849\n",
      "Epoch: 19............. Loss: 1.0146\n",
      "pk: 63.50 %\n",
      "Learning rate: 0.0002191123\n",
      "Epoch: 20............. Loss: 0.7582\n",
      "pk: 71.20 %\n",
      "Learning rate: 0.0002278768\n",
      "Epoch: 21............. Loss: 0.8704\n",
      "pk: 70.67 %\n",
      "Learning rate: 0.0002369919\n",
      "Epoch: 22............. Loss: 0.7934\n",
      "pk: 75.97 %\n",
      "Learning rate: 0.0002464716\n",
      "Epoch: 23............. Loss: 0.6490\n",
      "pk: 76.80 %\n",
      "Learning rate: 0.0002563304\n",
      "Epoch: 24............. Loss: 0.6210\n",
      "pk: 78.73 %\n",
      "Learning rate: 0.0002665836\n",
      "Epoch: 25............. Loss: 0.8191\n",
      "pk: 78.70 %\n",
      "Learning rate: 0.0002772470\n",
      "Epoch: 26............. Loss: 0.7540\n",
      "pk: 78.07 %\n",
      "Learning rate: 0.0002883369\n",
      "Epoch: 27............. Loss: 0.4263\n",
      "pk: 77.53 %\n",
      "Learning rate: 0.0002998703\n",
      "Epoch: 28............. Loss: 0.4971\n",
      "pk: 79.47 %\n",
      "Learning rate: 0.0003118651\n",
      "Epoch: 29............. Loss: 0.4337\n",
      "pk: 80.70 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 30............. Loss: 0.4230\n",
      "pk: 81.57 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 31............. Loss: 0.8125\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 32............. Loss: 0.5080\n",
      "pk: 81.43 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 33............. Loss: 0.6137\n",
      "pk: 82.50 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 34............. Loss: 0.8018\n",
      "pk: 82.77 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 35............. Loss: 0.5478\n",
      "pk: 84.00 %\n",
      "Learning rate: 0.0003794316\n",
      "Epoch: 36............. Loss: 0.5950\n",
      "pk: 84.23 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 37............. Loss: 0.2681\n",
      "pk: 83.37 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 38............. Loss: 0.4679\n",
      "pk: 84.30 %\n",
      "Learning rate: 0.0004103933\n",
      "Epoch: 39............. Loss: 0.3828\n",
      "pk: 83.47 %\n",
      "Learning rate: 0.0004268090\n",
      "Epoch: 40............. Loss: 0.5601\n",
      "pk: 84.60 %\n",
      "Learning rate: 0.0004268090\n",
      "Epoch: 41............. Loss: 0.3586\n",
      "pk: 84.57 %\n",
      "Learning rate: 0.0004438813\n",
      "Epoch: 42............. Loss: 0.5094\n",
      "pk: 84.87 %\n",
      "Learning rate: 0.0004616366\n",
      "Epoch: 43............. Loss: 0.2869\n",
      "pk: 84.70 %\n",
      "Learning rate: 0.0004801021\n",
      "Epoch: 44............. Loss: 0.3468\n",
      "pk: 85.57 %\n",
      "Learning rate: 0.0004993061\n",
      "Epoch: 45............. Loss: 0.4048\n",
      "pk: 84.63 %\n",
      "Learning rate: 0.0005192784\n",
      "Epoch: 46............. Loss: 0.3701\n",
      "pk: 84.27 %\n",
      "Learning rate: 0.0005400495\n",
      "Epoch: 47............. Loss: 0.2492\n",
      "pk: 84.67 %\n",
      "Learning rate: 0.0005616515\n",
      "Epoch: 48............. Loss: 0.7192\n",
      "pk: 85.80 %\n",
      "Learning rate: 0.0005841176\n",
      "Epoch: 49............. Loss: 0.4952\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.8114\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.7793\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 1.8067\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.7972\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 1.7850\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 1.7888\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 1.8176\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 1.8158\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 1.7717\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 1.7652\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 1.7891\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 1.7892\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001601032\n",
      "Epoch: 12............. Loss: 1.8010\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001665074\n",
      "Epoch: 13............. Loss: 1.7903\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001731676\n",
      "Epoch: 14............. Loss: 1.7924\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001800944\n",
      "Epoch: 15............. Loss: 1.8004\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001872981\n",
      "Epoch: 16............. Loss: 1.8008\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0001947900\n",
      "Epoch: 17............. Loss: 1.7895\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0002025817\n",
      "Epoch: 18............. Loss: 1.8091\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0002106849\n",
      "Epoch: 19............. Loss: 1.7852\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0002191123\n",
      "Epoch: 20............. Loss: 1.7987\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0002278768\n",
      "Epoch: 21............. Loss: 1.7965\n",
      "pk: 16.70 %\n",
      "Learning rate: 0.0002369919\n",
      "Epoch: 22............. Loss: 1.7957\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002464716\n",
      "Epoch: 23............. Loss: 1.7927\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002563304\n",
      "Epoch: 24............. Loss: 1.7875\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002665836\n",
      "Epoch: 25............. Loss: 1.7919\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002772470\n",
      "Epoch: 26............. Loss: 1.7867\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002883369\n",
      "Epoch: 27............. Loss: 1.8019\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002998703\n",
      "Epoch: 28............. Loss: 1.7910\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003118651\n",
      "Epoch: 29............. Loss: 1.7886\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 30............. Loss: 1.7947\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 31............. Loss: 1.7886\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 32............. Loss: 1.7871\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 33............. Loss: 1.7761\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 34............. Loss: 1.7910\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003794316\n",
      "Epoch: 35............. Loss: 1.7827\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 36............. Loss: 1.7849\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 37............. Loss: 1.7915\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 38............. Loss: 1.7961\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 39............. Loss: 1.8098\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004103933\n",
      "Epoch: 40............. Loss: 1.7941\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004268090\n",
      "Epoch: 41............. Loss: 1.7934\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004268090\n",
      "Epoch: 42............. Loss: 1.8047\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004438813\n",
      "Epoch: 43............. Loss: 1.7890\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004438813\n",
      "Epoch: 44............. Loss: 1.7971\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004438813\n",
      "Epoch: 45............. Loss: 1.7857\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004616366\n",
      "Epoch: 46............. Loss: 1.7887\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004801021\n",
      "Epoch: 47............. Loss: 1.7906\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004801021\n",
      "Epoch: 48............. Loss: 1.7883\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004993061\n",
      "Epoch: 49............. Loss: 1.7868\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.7926\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.7855\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 1.8297\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.8002\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 1.8075\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 1.7999\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 1.7893\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 1.7915\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 1.8045\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 1.8018\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 1.7965\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 1.7784\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001601032\n",
      "Epoch: 12............. Loss: 1.7793\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001665074\n",
      "Epoch: 13............. Loss: 1.7928\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001731676\n",
      "Epoch: 14............. Loss: 1.8104\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001800944\n",
      "Epoch: 15............. Loss: 1.7880\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001872981\n",
      "Epoch: 16............. Loss: 1.8004\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001947900\n",
      "Epoch: 17............. Loss: 1.7963\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002025817\n",
      "Epoch: 18............. Loss: 1.7989\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002106849\n",
      "Epoch: 19............. Loss: 1.7944\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002191123\n",
      "Epoch: 20............. Loss: 1.7965\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002278768\n",
      "Epoch: 21............. Loss: 1.7913\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002369919\n",
      "Epoch: 22............. Loss: 1.7946\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002464716\n",
      "Epoch: 23............. Loss: 1.7900\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002563304\n",
      "Epoch: 24............. Loss: 1.7979\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002665836\n",
      "Epoch: 25............. Loss: 1.7869\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002772470\n",
      "Epoch: 26............. Loss: 1.7859\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002883369\n",
      "Epoch: 27............. Loss: 1.7906\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002883369\n",
      "Epoch: 28............. Loss: 1.8002\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0002998703\n",
      "Epoch: 29............. Loss: 1.7914\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003118651\n",
      "Epoch: 30............. Loss: 1.7915\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003118651\n",
      "Epoch: 31............. Loss: 1.7897\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 32............. Loss: 1.7781\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 33............. Loss: 1.7944\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003243398\n",
      "Epoch: 34............. Loss: 1.7863\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 35............. Loss: 1.7854\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 36............. Loss: 1.7879\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003373133\n",
      "Epoch: 37............. Loss: 1.7909\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 38............. Loss: 1.7857\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003508059\n",
      "Epoch: 39............. Loss: 1.7980\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 40............. Loss: 1.7874\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 41............. Loss: 1.7892\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003648381\n",
      "Epoch: 42............. Loss: 1.7917\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003794316\n",
      "Epoch: 43............. Loss: 1.7919\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003794316\n",
      "Epoch: 44............. Loss: 1.7915\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 45............. Loss: 1.7810\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 46............. Loss: 1.7863\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0003946089\n",
      "Epoch: 47............. Loss: 1.7959\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004103933\n",
      "Epoch: 48............. Loss: 1.7936\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0004103933\n",
      "Epoch: 49............. Loss: 1.7934\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 6\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 76, 76]               0               0\n",
      "          Conv2d-5       [1, 86, 76, 76]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 76, 76]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 39, 39]               0               0\n",
      "          Conv2d-8      [1, 128, 39, 39]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 39, 39]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 20, 20]               0               0\n",
      "         Conv2d-11      [1, 128, 20, 20]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 20, 20]         409,728         409,728\n",
      "      MaxPool2d-13      [1, 128, 11, 11]               0               0\n",
      "         Conv2d-14      [1, 128, 11, 11]         409,728         409,728\n",
      "         Conv2d-15      [1, 128, 11, 11]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 6, 6]               0               0\n",
      "         Conv2d-17        [1, 128, 6, 6]         409,728         409,728\n",
      "         Linear-18              [1, 128]         589,952         589,952\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 4,140,460\n",
      "Trainable params: 4,140,460\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.7910\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.7817\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 1.7804\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.7866\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 1.7984\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 1.7846\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 1.7828\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 1.7890\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 1.7942\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 1.7875\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 1.7936\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 1.7964\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22172/1666218247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         model = TrainModel(dataset=IntelDataset(), method=method, input_size=input_size,\n\u001b[0;32m      9\u001b[0m                             c_kernels=[7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch)\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./output_data/data_plots/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./output_data/data_plots/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_t.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Magda\\Desktop\\CNN-filters\\TrainModel.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[0mloss_train_temp\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mloss_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_train_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = 150\n",
    "epoch = 50\n",
    "dataset_name = \"intel\"\n",
    "methods = ['xavier_uniform_M_14', 'xavier_uniform_M_20', 'xavier_uniform_M_2', 'xavier_uniform_M_1',]\n",
    "\n",
    "for method in methods:\n",
    "    for apt in range(3, 6):\n",
    "        model = TrainModel(dataset=IntelDataset(), method=method, input_size=input_size,\n",
    "                            c_kernels=[7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + method + \"_\" + str(apt))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
