{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from CifarDataset import CifarDataset\n",
    "from IntelDataset import IntelDataset\n",
    "from TrainModel import TrainModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 31.25 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.7939\n",
      "pk: 46.14 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.3159\n",
      "pk: 55.24 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.1740\n",
      "pk: 61.14 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.0057\n",
      "pk: 62.65 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.0143\n",
      "pk: 67.74 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.8479\n",
      "pk: 69.73 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.7958\n",
      "pk: 69.97 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.9726\n",
      "pk: 71.43 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.8131\n",
      "pk: 72.65 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.8669\n",
      "pk: 74.02 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.7906\n",
      "pk: 72.45 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.8359\n",
      "pk: 73.86 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.5690\n",
      "pk: 72.68 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.7145\n",
      "pk: 73.03 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 14............. Loss: 0.8723\n",
      "pk: 74.86 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 15............. Loss: 0.6127\n",
      "pk: 74.01 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 16............. Loss: 0.6397\n",
      "pk: 74.58 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 17............. Loss: 0.8122\n",
      "pk: 74.61 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 18............. Loss: 0.4540\n",
      "pk: 73.45 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 19............. Loss: 0.6781\n",
      "pk: 73.43 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 20............. Loss: 0.7271\n",
      "pk: 73.14 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 21............. Loss: 0.6358\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 22............. Loss: 0.4500\n",
      "pk: 73.19 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 23............. Loss: 0.6440\n",
      "pk: 74.16 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 24............. Loss: 0.5986\n",
      "pk: 74.37 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 25............. Loss: 0.7969\n",
      "pk: 75.86 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 26............. Loss: 0.5326\n",
      "pk: 75.07 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 27............. Loss: 0.5761\n",
      "pk: 73.78 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 28............. Loss: 0.6268\n",
      "pk: 75.62 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 29............. Loss: 0.5474\n",
      "pk: 74.88 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 30............. Loss: 0.9123\n",
      "pk: 74.68 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 31............. Loss: 0.6402\n",
      "pk: 75.80 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 32............. Loss: 0.7614\n",
      "pk: 73.89 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 33............. Loss: 0.5466\n",
      "pk: 75.52 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 34............. Loss: 0.5589\n",
      "pk: 73.47 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 35............. Loss: 0.7305\n",
      "pk: 74.70 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 36............. Loss: 0.7988\n",
      "pk: 76.14 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 37............. Loss: 0.6106\n",
      "pk: 75.77 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 38............. Loss: 0.5692\n",
      "pk: 74.36 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 39............. Loss: 0.7075\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 41.45 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.5010\n",
      "pk: 53.95 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.2134\n",
      "pk: 60.91 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.0013\n",
      "pk: 63.57 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 0.9494\n",
      "pk: 65.81 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 0.9854\n",
      "pk: 68.24 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 1.0298\n",
      "pk: 69.06 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.6941\n",
      "pk: 69.70 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.8760\n",
      "pk: 72.32 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.9353\n",
      "pk: 72.13 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.7421\n",
      "pk: 73.63 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.8575\n",
      "pk: 74.24 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.7067\n",
      "pk: 71.94 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.6443\n",
      "pk: 73.56 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.6956\n",
      "pk: 71.08 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 0.6261\n",
      "pk: 74.02 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.7987\n",
      "pk: 73.94 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.5901\n",
      "pk: 74.35 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 17............. Loss: 0.7546\n",
      "pk: 73.06 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 18............. Loss: 0.6598\n",
      "pk: 74.74 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 19............. Loss: 0.6668\n",
      "pk: 74.17 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 20............. Loss: 0.5622\n",
      "pk: 74.94 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 21............. Loss: 0.6990\n",
      "pk: 75.36 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 22............. Loss: 0.5988\n",
      "pk: 73.40 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 23............. Loss: 0.6727\n",
      "pk: 74.83 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 24............. Loss: 0.8381\n",
      "pk: 75.31 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 25............. Loss: 0.5366\n",
      "pk: 74.55 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 26............. Loss: 0.7150\n",
      "pk: 73.93 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 27............. Loss: 0.7592\n",
      "pk: 74.46 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 28............. Loss: 0.6041\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 29............. Loss: 0.8426\n",
      "pk: 75.84 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 30............. Loss: 0.6318\n",
      "pk: 75.05 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 31............. Loss: 0.6716\n",
      "pk: 75.21 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 32............. Loss: 0.5165\n",
      "pk: 75.58 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 33............. Loss: 0.5093\n",
      "pk: 75.40 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 34............. Loss: 0.4932\n",
      "pk: 74.52 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 35............. Loss: 0.8502\n",
      "pk: 73.60 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 36............. Loss: 0.7322\n",
      "pk: 75.02 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 37............. Loss: 0.9361\n",
      "pk: 75.07 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 38............. Loss: 0.5540\n",
      "pk: 74.16 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 39............. Loss: 0.6093\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 37.36 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.6528\n",
      "pk: 51.88 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.3138\n",
      "pk: 59.71 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.0204\n",
      "pk: 64.02 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 0.9651\n",
      "pk: 68.18 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.0645\n",
      "pk: 69.46 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 0.9260\n",
      "pk: 70.89 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 0.9617\n",
      "pk: 71.05 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.9673\n",
      "pk: 72.21 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 0.8236\n",
      "pk: 72.44 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.9407\n",
      "pk: 74.11 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.8245\n",
      "pk: 72.31 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.6631\n",
      "pk: 74.08 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.8820\n",
      "pk: 74.23 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.6399\n",
      "pk: 75.50 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 0.6508\n",
      "pk: 74.81 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.8016\n",
      "pk: 75.00 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.7115\n",
      "pk: 75.47 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 17............. Loss: 0.5500\n",
      "pk: 75.38 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 18............. Loss: 0.5957\n",
      "pk: 75.18 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 19............. Loss: 0.8025\n",
      "pk: 74.49 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 20............. Loss: 0.6018\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 21............. Loss: 0.7069\n",
      "pk: 75.37 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 22............. Loss: 0.7203\n",
      "pk: 74.71 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 23............. Loss: 0.6996\n",
      "pk: 75.37 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 24............. Loss: 0.7937\n",
      "pk: 74.61 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 25............. Loss: 0.8290\n",
      "pk: 75.87 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 26............. Loss: 0.7744\n",
      "pk: 73.86 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 27............. Loss: 0.7086\n",
      "pk: 74.84 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 28............. Loss: 0.6229\n",
      "pk: 75.51 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 29............. Loss: 0.8259\n",
      "pk: 75.72 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 30............. Loss: 0.5752\n",
      "pk: 75.29 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 31............. Loss: 0.6108\n",
      "pk: 74.29 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 32............. Loss: 0.8677\n",
      "pk: 73.74 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 33............. Loss: 0.7938\n",
      "pk: 73.96 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 34............. Loss: 0.8292\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 35............. Loss: 0.7315\n",
      "pk: 74.89 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 36............. Loss: 0.7996\n",
      "pk: 73.60 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 37............. Loss: 0.6945\n",
      "pk: 73.12 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 38............. Loss: 0.6657\n",
      "pk: 75.03 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 39............. Loss: 0.7332\n"
     ]
    }
   ],
   "source": [
    "# input image size in px (square image)\n",
    "input_size = 32\n",
    "dataset_name = \"cifar\"\n",
    "epoch = 40\n",
    "0\n",
    "\n",
    "# methods = [\"xavier_uniform\",'xavier_uniform_M_10', 'xavier_uniform_M_2', 'xavier_uniform_M_1', 'xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "methods = ['kaiming_uniform']\n",
    "for method in methods:\n",
    "    for apt in range(3):\n",
    "        model = TrainModel(dataset=CifarDataset(), method=method, input_size=input_size,\n",
    "                                c_kernels=[5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch, activation_relu=True)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + dataset_name + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + dataset_name + method + \"_\" + str(apt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 15\n",
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1      [1, 16, 34, 34]             448             448\n",
      "       MaxPool2d-2      [1, 16, 18, 18]               0               0\n",
      "          Conv2d-3      [1, 32, 20, 20]           4,640           4,640\n",
      "          Conv2d-4      [1, 64, 22, 22]          18,496          18,496\n",
      "          Conv2d-5      [1, 86, 24, 24]          49,622          49,622\n",
      "       MaxPool2d-6      [1, 86, 13, 13]               0               0\n",
      "          Conv2d-7     [1, 128, 15, 15]          99,200          99,200\n",
      "          Linear-8              [1, 64]       1,843,264       1,843,264\n",
      "          Linear-9              [1, 16]           1,040           1,040\n",
      "         Linear-10              [1, 10]             170             170\n",
      "========================================================================\n",
      "Total params: 2,016,880\n",
      "Trainable params: 2,016,880\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 11.54 %\n",
      "Learning rate: 0.0000100000\n",
      "Epoch: 0............. Loss: 2.2749\n",
      "pk: 13.43 %\n",
      "Learning rate: 0.0000104000\n",
      "Epoch: 1............. Loss: 2.2687\n",
      "pk: 17.82 %\n",
      "Learning rate: 0.0000108160\n",
      "Epoch: 2............. Loss: 2.2650\n",
      "pk: 21.71 %\n",
      "Learning rate: 0.0000112486\n",
      "Epoch: 3............. Loss: 2.2529\n",
      "pk: 24.07 %\n",
      "Learning rate: 0.0000116986\n",
      "Epoch: 4............. Loss: 2.2436\n",
      "pk: 25.55 %\n",
      "Learning rate: 0.0000121665\n",
      "Epoch: 5............. Loss: 2.1919\n",
      "pk: 26.00 %\n",
      "Learning rate: 0.0000126532\n",
      "Epoch: 6............. Loss: 2.2056\n",
      "pk: 26.48 %\n",
      "Learning rate: 0.0000131593\n",
      "Epoch: 7............. Loss: 2.1701\n",
      "pk: 27.40 %\n",
      "Learning rate: 0.0000136857\n",
      "Epoch: 8............. Loss: 2.1604\n",
      "pk: 27.76 %\n",
      "Learning rate: 0.0000142331\n",
      "Epoch: 9............. Loss: 2.0993\n",
      "pk: 28.61 %\n",
      "Learning rate: 0.0000148024\n",
      "Epoch: 10............. Loss: 2.1658\n",
      "pk: 29.25 %\n",
      "Learning rate: 0.0000153945\n",
      "Epoch: 11............. Loss: 2.1528\n",
      "pk: 29.80 %\n",
      "Learning rate: 0.0000160103\n",
      "Epoch: 12............. Loss: 2.0790\n",
      "pk: 30.02 %\n",
      "Learning rate: 0.0000166507\n",
      "Epoch: 13............. Loss: 2.1539\n",
      "pk: 30.81 %\n",
      "Learning rate: 0.0000173168\n",
      "Epoch: 14............. Loss: 2.1415\n",
      "pk: 31.88 %\n",
      "Learning rate: 0.0000180094\n",
      "Epoch: 15............. Loss: 2.0788\n",
      "pk: 32.66 %\n",
      "Learning rate: 0.0000187298\n",
      "Epoch: 16............. Loss: 2.0431\n",
      "pk: 33.80 %\n",
      "Learning rate: 0.0000194790\n",
      "Epoch: 17............. Loss: 1.9587\n",
      "pk: 35.25 %\n",
      "Learning rate: 0.0000202582\n",
      "Epoch: 18............. Loss: 1.9615\n",
      "pk: 36.08 %\n",
      "Learning rate: 0.0000210685\n",
      "Epoch: 19............. Loss: 1.9206\n",
      "pk: 37.16 %\n",
      "Learning rate: 0.0000219112\n",
      "Epoch: 20............. Loss: 1.9887\n",
      "pk: 37.40 %\n",
      "Learning rate: 0.0000227877\n",
      "Epoch: 21............. Loss: 1.8868\n",
      "pk: 38.08 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 22............. Loss: 1.9073\n",
      "pk: 39.28 %\n",
      "Learning rate: 0.0000246472\n",
      "Epoch: 23............. Loss: 1.8426\n",
      "pk: 40.84 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 24............. Loss: 1.6535\n",
      "pk: 41.26 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 25............. Loss: 1.7762\n",
      "pk: 42.27 %\n",
      "Learning rate: 0.0000277247\n",
      "Epoch: 26............. Loss: 1.8243\n",
      "pk: 42.78 %\n",
      "Learning rate: 0.0000288337\n",
      "Epoch: 27............. Loss: 1.7068\n",
      "pk: 43.52 %\n",
      "Learning rate: 0.0000299870\n",
      "Epoch: 28............. Loss: 1.7006\n",
      "pk: 43.76 %\n",
      "Learning rate: 0.0000311865\n",
      "Epoch: 29............. Loss: 1.6787\n",
      "pk: 44.72 %\n",
      "Learning rate: 0.0000324340\n",
      "Epoch: 30............. Loss: 1.6920\n",
      "pk: 45.34 %\n",
      "Learning rate: 0.0000337313\n",
      "Epoch: 31............. Loss: 1.6773\n",
      "pk: 45.51 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 32............. Loss: 1.6708\n",
      "pk: 46.61 %\n",
      "Learning rate: 0.0000364838\n",
      "Epoch: 33............. Loss: 1.6713\n",
      "pk: 47.07 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 34............. Loss: 1.5447\n",
      "pk: 47.48 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 35............. Loss: 1.4586\n",
      "pk: 47.73 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 36............. Loss: 1.4654\n",
      "pk: 47.86 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 37............. Loss: 1.7108\n",
      "pk: 48.46 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 38............. Loss: 1.3855\n",
      "pk: 50.04 %\n",
      "Learning rate: 0.0000461637\n",
      "Epoch: 39............. Loss: 1.5306\n",
      "pk: 49.29 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 40............. Loss: 1.3693\n",
      "pk: 50.23 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 41............. Loss: 1.6523\n",
      "pk: 51.19 %\n",
      "Learning rate: 0.0000519278\n",
      "Epoch: 42............. Loss: 1.4926\n",
      "pk: 51.56 %\n",
      "Learning rate: 0.0000540050\n",
      "Epoch: 43............. Loss: 1.3905\n",
      "pk: 51.99 %\n",
      "Learning rate: 0.0000561652\n",
      "Epoch: 44............. Loss: 1.5313\n",
      "pk: 51.52 %\n",
      "Learning rate: 0.0000584118\n",
      "Epoch: 45............. Loss: 1.3301\n",
      "pk: 52.68 %\n",
      "Learning rate: 0.0000607482\n",
      "Epoch: 46............. Loss: 1.5337\n",
      "pk: 53.39 %\n",
      "Learning rate: 0.0000631782\n",
      "Epoch: 47............. Loss: 1.4731\n",
      "pk: 53.45 %\n",
      "Learning rate: 0.0000657053\n",
      "Epoch: 48............. Loss: 1.4202\n",
      "pk: 53.99 %\n",
      "Learning rate: 0.0000683335\n",
      "Epoch: 49............. Loss: 1.3270\n",
      "pk: 55.01 %\n",
      "Learning rate: 0.0000710668\n",
      "Epoch: 50............. Loss: 1.4637\n",
      "pk: 55.58 %\n",
      "Learning rate: 0.0000739095\n",
      "Epoch: 51............. Loss: 1.4297\n",
      "pk: 55.47 %\n",
      "Learning rate: 0.0000768659\n",
      "Epoch: 52............. Loss: 1.2283\n",
      "pk: 56.70 %\n",
      "Learning rate: 0.0000799405\n",
      "Epoch: 53............. Loss: 1.3096\n",
      "pk: 57.41 %\n",
      "Learning rate: 0.0000831381\n",
      "Epoch: 54............. Loss: 1.3728\n",
      "pk: 58.31 %\n",
      "Learning rate: 0.0000864637\n",
      "Epoch: 55............. Loss: 1.2719\n",
      "pk: 57.99 %\n",
      "Learning rate: 0.0000899222\n",
      "Epoch: 56............. Loss: 1.4430\n",
      "pk: 58.51 %\n",
      "Learning rate: 0.0000935191\n",
      "Epoch: 57............. Loss: 1.0922\n",
      "pk: 58.21 %\n",
      "Learning rate: 0.0000972599\n",
      "Epoch: 58............. Loss: 1.3853\n",
      "pk: 59.72 %\n",
      "Learning rate: 0.0001011503\n",
      "Epoch: 59............. Loss: 1.2653\n",
      "pk: 59.86 %\n",
      "Learning rate: 0.0001051963\n",
      "Epoch: 60............. Loss: 1.2437\n",
      "pk: 58.79 %\n",
      "Learning rate: 0.0001094041\n",
      "Epoch: 61............. Loss: 1.2770\n",
      "pk: 61.16 %\n",
      "Learning rate: 0.0001137803\n",
      "Epoch: 62............. Loss: 1.2430\n",
      "pk: 59.84 %\n",
      "Learning rate: 0.0001183315\n",
      "Epoch: 63............. Loss: 1.0947\n",
      "pk: 61.08 %\n",
      "Learning rate: 0.0001230648\n",
      "Epoch: 64............. Loss: 1.1421\n",
      "pk: 62.38 %\n",
      "Learning rate: 0.0001279874\n",
      "Epoch: 65............. Loss: 1.3414\n",
      "pk: 61.96 %\n",
      "Learning rate: 0.0001331068\n",
      "Epoch: 66............. Loss: 1.2137\n",
      "pk: 63.32 %\n",
      "Learning rate: 0.0001384311\n",
      "Epoch: 67............. Loss: 0.9827\n",
      "pk: 62.49 %\n",
      "Learning rate: 0.0001439684\n",
      "Epoch: 68............. Loss: 1.0287\n",
      "pk: 64.52 %\n",
      "Learning rate: 0.0001497271\n",
      "Epoch: 69............. Loss: 1.0856\n",
      "pk: 64.22 %\n",
      "Learning rate: 0.0001557162\n",
      "Epoch: 70............. Loss: 0.9246\n",
      "pk: 63.51 %\n",
      "Learning rate: 0.0001619448\n",
      "Epoch: 71............. Loss: 1.2770\n",
      "pk: 64.70 %\n",
      "Learning rate: 0.0001684226\n",
      "Epoch: 72............. Loss: 1.1551\n",
      "pk: 65.66 %\n",
      "Learning rate: 0.0001751595\n",
      "Epoch: 73............. Loss: 0.9509\n",
      "pk: 64.66 %\n",
      "Learning rate: 0.0001821659\n",
      "Epoch: 74............. Loss: 0.9384\n",
      "pk: 65.07 %\n",
      "Learning rate: 0.0001894525\n",
      "Epoch: 75............. Loss: 0.9500\n",
      "pk: 65.96 %\n",
      "Learning rate: 0.0001970306\n",
      "Epoch: 76............. Loss: 1.1485\n",
      "pk: 66.02 %\n",
      "Learning rate: 0.0002049119\n",
      "Epoch: 77............. Loss: 1.1552\n",
      "pk: 66.90 %\n",
      "Learning rate: 0.0002131083\n",
      "Epoch: 78............. Loss: 0.9296\n",
      "pk: 66.88 %\n",
      "Learning rate: 0.0002216327\n",
      "Epoch: 79............. Loss: 0.9467\n",
      "pk: 65.59 %\n",
      "Learning rate: 0.0002304980\n",
      "Epoch: 80............. Loss: 0.8416\n",
      "pk: 67.69 %\n",
      "Learning rate: 0.0002397179\n",
      "Epoch: 81............. Loss: 0.8228\n",
      "pk: 66.65 %\n",
      "Learning rate: 0.0002493066\n",
      "Epoch: 82............. Loss: 0.8148\n",
      "pk: 66.08 %\n",
      "Learning rate: 0.0002592789\n",
      "Epoch: 83............. Loss: 0.6855\n",
      "pk: 66.58 %\n",
      "Learning rate: 0.0002696500\n",
      "Epoch: 84............. Loss: 0.9112\n",
      "pk: 68.01 %\n",
      "Learning rate: 0.0002804360\n",
      "Epoch: 85............. Loss: 0.9798\n",
      "pk: 68.08 %\n",
      "Learning rate: 0.0002916535\n",
      "Epoch: 86............. Loss: 0.8778\n",
      "pk: 68.63 %\n",
      "Learning rate: 0.0003033196\n",
      "Epoch: 87............. Loss: 0.8697\n",
      "pk: 69.30 %\n",
      "Learning rate: 0.0003154524\n",
      "Epoch: 88............. Loss: 0.8333\n",
      "pk: 68.94 %\n",
      "Learning rate: 0.0003280705\n",
      "Epoch: 89............. Loss: 0.6614\n",
      "pk: 70.19 %\n",
      "Learning rate: 0.0003411933\n",
      "Epoch: 90............. Loss: 0.6960\n",
      "pk: 69.73 %\n",
      "Learning rate: 0.0003548411\n",
      "Epoch: 91............. Loss: 0.8771\n",
      "pk: 70.39 %\n",
      "Learning rate: 0.0003690347\n",
      "Epoch: 92............. Loss: 0.7282\n",
      "pk: 68.54 %\n",
      "Learning rate: 0.0003837961\n",
      "Epoch: 93............. Loss: 0.7482\n",
      "pk: 70.54 %\n",
      "Learning rate: 0.0003991479\n",
      "Epoch: 94............. Loss: 0.6270\n",
      "pk: 70.45 %\n",
      "Learning rate: 0.0004151139\n",
      "Epoch: 95............. Loss: 0.6954\n",
      "pk: 70.22 %\n",
      "Learning rate: 0.0004317184\n",
      "Epoch: 96............. Loss: 0.7604\n",
      "pk: 69.64 %\n",
      "Learning rate: 0.0004489872\n",
      "Epoch: 97............. Loss: 0.5314\n",
      "pk: 69.16 %\n",
      "Learning rate: 0.0004669466\n",
      "Epoch: 98............. Loss: 0.8251\n",
      "pk: 70.80 %\n",
      "Learning rate: 0.0004856245\n",
      "Epoch: 99............. Loss: 0.6562\n",
      "pk: 71.56 %\n",
      "Learning rate: 0.0005050495\n",
      "Epoch: 100............. Loss: 0.5928\n",
      "pk: 71.85 %\n",
      "Learning rate: 0.0005252515\n",
      "Epoch: 101............. Loss: 0.5201\n",
      "pk: 70.95 %\n",
      "Learning rate: 0.0005462615\n",
      "Epoch: 102............. Loss: 0.6326\n",
      "pk: 71.01 %\n",
      "Learning rate: 0.0005681120\n",
      "Epoch: 103............. Loss: 0.4920\n",
      "pk: 71.81 %\n",
      "Learning rate: 0.0005908365\n",
      "Epoch: 104............. Loss: 0.6952\n",
      "pk: 71.72 %\n",
      "Learning rate: 0.0006144699\n",
      "Epoch: 105............. Loss: 0.6312\n",
      "pk: 72.11 %\n",
      "Learning rate: 0.0006390487\n",
      "Epoch: 106............. Loss: 0.5369\n",
      "pk: 71.43 %\n",
      "Learning rate: 0.0006646107\n",
      "Epoch: 107............. Loss: 0.5573\n",
      "pk: 71.67 %\n",
      "Learning rate: 0.0006911951\n",
      "Epoch: 108............. Loss: 0.5803\n",
      "pk: 72.02 %\n",
      "Learning rate: 0.0007188429\n",
      "Epoch: 109............. Loss: 0.4803\n",
      "pk: 71.94 %\n",
      "Learning rate: 0.0007475966\n",
      "Epoch: 110............. Loss: 0.4821\n",
      "pk: 71.68 %\n",
      "Learning rate: 0.0007775005\n",
      "Epoch: 111............. Loss: 0.5068\n",
      "pk: 70.90 %\n",
      "Learning rate: 0.0008086005\n",
      "Epoch: 112............. Loss: 0.4671\n",
      "pk: 71.89 %\n",
      "Learning rate: 0.0008409445\n",
      "Epoch: 113............. Loss: 0.3799\n",
      "pk: 71.65 %\n",
      "Learning rate: 0.0008745823\n",
      "Epoch: 114............. Loss: 0.4864\n",
      "pk: 72.58 %\n",
      "Learning rate: 0.0009095656\n",
      "Epoch: 115............. Loss: 0.4934\n",
      "pk: 71.42 %\n",
      "Learning rate: 0.0009459482\n",
      "Epoch: 116............. Loss: 0.2615\n",
      "pk: 71.74 %\n",
      "Learning rate: 0.0009837861\n",
      "Epoch: 117............. Loss: 0.3969\n",
      "pk: 71.35 %\n",
      "Learning rate: 0.0010231376\n",
      "Epoch: 118............. Loss: 0.3819\n",
      "pk: 71.00 %\n",
      "Learning rate: 0.0010640631\n",
      "Epoch: 119............. Loss: 0.6539\n",
      "pk: 71.99 %\n",
      "Learning rate: 0.0011066256\n",
      "Epoch: 120............. Loss: 0.3190\n",
      "pk: 71.67 %\n",
      "Learning rate: 0.0011508906\n",
      "Epoch: 121............. Loss: 0.4656\n",
      "pk: 71.46 %\n",
      "Learning rate: 0.0011969263\n",
      "Epoch: 122............. Loss: 0.3215\n",
      "pk: 71.66 %\n",
      "Learning rate: 0.0012448033\n",
      "Epoch: 123............. Loss: 0.2911\n",
      "pk: 71.75 %\n",
      "Learning rate: 0.0012945954\n",
      "Epoch: 124............. Loss: 0.3253\n",
      "pk: 71.40 %\n",
      "Learning rate: 0.0012945954\n",
      "Epoch: 125............. Loss: 0.3658\n",
      "pk: 70.55 %\n",
      "Learning rate: 0.0013463793\n",
      "Epoch: 126............. Loss: 0.3104\n",
      "pk: 72.01 %\n",
      "Learning rate: 0.0014002344\n",
      "Epoch: 127............. Loss: 0.4732\n",
      "pk: 71.52 %\n",
      "Learning rate: 0.0014562438\n",
      "Epoch: 128............. Loss: 0.4039\n",
      "pk: 72.36 %\n",
      "Learning rate: 0.0015144936\n",
      "Epoch: 129............. Loss: 0.1683\n",
      "pk: 71.77 %\n",
      "Learning rate: 0.0015750733\n",
      "Epoch: 130............. Loss: 0.2910\n",
      "pk: 71.12 %\n",
      "Learning rate: 0.0015750733\n",
      "Epoch: 131............. Loss: 0.3010\n",
      "pk: 72.49 %\n",
      "Learning rate: 0.0016380762\n",
      "Epoch: 132............. Loss: 0.2804\n",
      "pk: 71.64 %\n",
      "Learning rate: 0.0017035993\n",
      "Epoch: 133............. Loss: 0.2410\n",
      "pk: 71.70 %\n",
      "Learning rate: 0.0017717433\n",
      "Epoch: 134............. Loss: 0.2750\n",
      "pk: 72.06 %\n",
      "Learning rate: 0.0018426130\n",
      "Epoch: 135............. Loss: 0.2779\n",
      "pk: 72.00 %\n",
      "Learning rate: 0.0018426130\n",
      "Epoch: 136............. Loss: 0.1697\n",
      "pk: 71.20 %\n",
      "Learning rate: 0.0019163175\n",
      "Epoch: 137............. Loss: 0.0949\n",
      "pk: 72.41 %\n",
      "Learning rate: 0.0019163175\n",
      "Epoch: 138............. Loss: 0.1921\n",
      "pk: 71.53 %\n",
      "Learning rate: 0.0019929702\n",
      "Epoch: 139............. Loss: 0.2494\n",
      "pk: 72.23 %\n",
      "Learning rate: 0.0019929702\n",
      "Epoch: 140............. Loss: 0.1600\n",
      "pk: 72.00 %\n",
      "Learning rate: 0.0020726890\n",
      "Epoch: 141............. Loss: 0.0941\n",
      "pk: 71.85 %\n",
      "Learning rate: 0.0020726890\n",
      "Epoch: 142............. Loss: 0.2200\n",
      "pk: 72.50 %\n",
      "Learning rate: 0.0021555966\n",
      "Epoch: 143............. Loss: 0.2593\n",
      "pk: 71.89 %\n",
      "Learning rate: 0.0022418204\n",
      "Epoch: 144............. Loss: 0.2120\n",
      "pk: 71.62 %\n",
      "Learning rate: 0.0022418204\n",
      "Epoch: 145............. Loss: 0.1475\n",
      "pk: 72.19 %\n",
      "Learning rate: 0.0023314933\n",
      "Epoch: 146............. Loss: 0.2924\n",
      "pk: 72.23 %\n",
      "Learning rate: 0.0023314933\n",
      "Epoch: 147............. Loss: 0.0802\n",
      "pk: 71.38 %\n",
      "Learning rate: 0.0024247530\n",
      "Epoch: 148............. Loss: 0.2470\n",
      "pk: 72.74 %\n",
      "Learning rate: 0.0025217431\n",
      "Epoch: 149............. Loss: 0.2767\n",
      "pk: 72.77 %\n",
      "Learning rate: 0.0025217431\n",
      "Epoch: 150............. Loss: 0.2617\n",
      "pk: 71.72 %\n",
      "Learning rate: 0.0026226128\n",
      "Epoch: 151............. Loss: 0.2652\n",
      "pk: 72.43 %\n",
      "Learning rate: 0.0026226128\n",
      "Epoch: 152............. Loss: 0.2481\n",
      "pk: 72.22 %\n",
      "Learning rate: 0.0027275173\n",
      "Epoch: 153............. Loss: 0.2345\n",
      "pk: 71.89 %\n",
      "Learning rate: 0.0028366180\n",
      "Epoch: 154............. Loss: 0.2262\n",
      "pk: 72.57 %\n",
      "Learning rate: 0.0028366180\n",
      "Epoch: 155............. Loss: 0.2332\n",
      "pk: 72.11 %\n",
      "Learning rate: 0.0029500828\n",
      "Epoch: 156............. Loss: 0.1597\n",
      "pk: 72.15 %\n",
      "Learning rate: 0.0029500828\n",
      "Epoch: 157............. Loss: 0.2402\n",
      "pk: 71.75 %\n",
      "Learning rate: 0.0030680861\n",
      "Epoch: 158............. Loss: 0.1571\n",
      "pk: 72.55 %\n",
      "Learning rate: 0.0030680861\n",
      "Epoch: 159............. Loss: 0.4351\n",
      "pk: 72.26 %\n",
      "Learning rate: 0.0031908095\n",
      "Epoch: 160............. Loss: 0.2533\n",
      "pk: 72.46 %\n",
      "Learning rate: 0.0031908095\n",
      "Epoch: 161............. Loss: 0.1763\n",
      "pk: 72.58 %\n",
      "Learning rate: 0.0033184419\n",
      "Epoch: 162............. Loss: 0.1861\n",
      "pk: 72.81 %\n",
      "Learning rate: 0.0034511796\n",
      "Epoch: 163............. Loss: 0.0832\n",
      "pk: 72.06 %\n",
      "Learning rate: 0.0034511796\n",
      "Epoch: 164............. Loss: 0.2050\n",
      "pk: 71.64 %\n",
      "Learning rate: 0.0035892267\n",
      "Epoch: 165............. Loss: 0.1688\n",
      "pk: 72.51 %\n",
      "Learning rate: 0.0035892267\n",
      "Epoch: 166............. Loss: 0.1267\n",
      "pk: 72.37 %\n",
      "Learning rate: 0.0037327958\n",
      "Epoch: 167............. Loss: 0.3289\n",
      "pk: 71.25 %\n",
      "Learning rate: 0.0037327958\n",
      "Epoch: 168............. Loss: 0.2470\n",
      "pk: 71.66 %\n",
      "Learning rate: 0.0038821076\n",
      "Epoch: 169............. Loss: 0.1914\n",
      "pk: 71.77 %\n",
      "Learning rate: 0.0038821076\n",
      "Epoch: 170............. Loss: 0.1739\n",
      "pk: 72.48 %\n",
      "Learning rate: 0.0040373919\n",
      "Epoch: 171............. Loss: 0.1069\n",
      "pk: 71.90 %\n",
      "Learning rate: 0.0041988876\n",
      "Epoch: 172............. Loss: 0.2400\n",
      "pk: 72.09 %\n",
      "Learning rate: 0.0041988876\n",
      "Epoch: 173............. Loss: 0.1762\n",
      "pk: 71.18 %\n",
      "Learning rate: 0.0043668431\n",
      "Epoch: 174............. Loss: 0.2260\n",
      "pk: 71.37 %\n",
      "Learning rate: 0.0043668431\n",
      "Epoch: 175............. Loss: 0.1883\n",
      "pk: 72.44 %\n",
      "Learning rate: 0.0043668431\n",
      "Epoch: 176............. Loss: 0.1807\n",
      "pk: 71.91 %\n",
      "Learning rate: 0.0045415169\n",
      "Epoch: 177............. Loss: 0.0929\n",
      "pk: 71.99 %\n",
      "Learning rate: 0.0045415169\n",
      "Epoch: 178............. Loss: 0.1124\n",
      "pk: 71.56 %\n",
      "Learning rate: 0.0047231775\n",
      "Epoch: 179............. Loss: 0.3682\n",
      "pk: 71.78 %\n",
      "Learning rate: 0.0047231775\n",
      "Epoch: 180............. Loss: 0.1887\n",
      "pk: 71.56 %\n",
      "Learning rate: 0.0049121046\n",
      "Epoch: 181............. Loss: 0.1670\n",
      "pk: 72.32 %\n",
      "Learning rate: 0.0049121046\n",
      "Epoch: 182............. Loss: 0.2035\n",
      "pk: 71.01 %\n",
      "Learning rate: 0.0051085888\n",
      "Epoch: 183............. Loss: 0.1407\n",
      "pk: 72.21 %\n",
      "Learning rate: 0.0051085888\n",
      "Epoch: 184............. Loss: 0.2180\n",
      "pk: 70.44 %\n",
      "Learning rate: 0.0051085888\n",
      "Epoch: 185............. Loss: 0.1482\n",
      "pk: 71.87 %\n",
      "Learning rate: 0.0053129324\n",
      "Epoch: 186............. Loss: 0.2868\n",
      "pk: 72.02 %\n",
      "Learning rate: 0.0055254497\n",
      "Epoch: 187............. Loss: 0.3347\n",
      "pk: 72.14 %\n",
      "Learning rate: 0.0055254497\n",
      "Epoch: 188............. Loss: 0.2018\n",
      "pk: 70.96 %\n",
      "Learning rate: 0.0057464677\n",
      "Epoch: 189............. Loss: 0.0770\n",
      "pk: 71.95 %\n",
      "Learning rate: 0.0057464677\n",
      "Epoch: 190............. Loss: 0.1803\n",
      "pk: 72.39 %\n",
      "Learning rate: 0.0059763264\n",
      "Epoch: 191............. Loss: 0.1267\n",
      "pk: 71.95 %\n",
      "Learning rate: 0.0059763264\n",
      "Epoch: 192............. Loss: 0.1828\n",
      "pk: 71.98 %\n",
      "Learning rate: 0.0062153794\n",
      "Epoch: 193............. Loss: 0.1033\n",
      "pk: 71.59 %\n",
      "Learning rate: 0.0062153794\n",
      "Epoch: 194............. Loss: 0.2166\n",
      "pk: 71.89 %\n",
      "Learning rate: 0.0064639946\n",
      "Epoch: 195............. Loss: 0.1909\n",
      "pk: 72.57 %\n",
      "Learning rate: 0.0067225544\n",
      "Epoch: 196............. Loss: 0.1172\n",
      "pk: 71.11 %\n",
      "Learning rate: 0.0067225544\n",
      "Epoch: 197............. Loss: 0.1768\n",
      "pk: 70.25 %\n",
      "Learning rate: 0.0069914565\n",
      "Epoch: 198............. Loss: 0.2780\n",
      "pk: 71.47 %\n",
      "Learning rate: 0.0069914565\n",
      "Epoch: 199............. Loss: 0.1261\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 15\n",
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1      [1, 16, 34, 34]             448             448\n",
      "       MaxPool2d-2      [1, 16, 18, 18]               0               0\n",
      "          Conv2d-3      [1, 32, 20, 20]           4,640           4,640\n",
      "          Conv2d-4      [1, 64, 22, 22]          18,496          18,496\n",
      "          Conv2d-5      [1, 86, 24, 24]          49,622          49,622\n",
      "       MaxPool2d-6      [1, 86, 13, 13]               0               0\n",
      "          Conv2d-7     [1, 128, 15, 15]          99,200          99,200\n",
      "          Linear-8              [1, 64]       1,843,264       1,843,264\n",
      "          Linear-9              [1, 16]           1,040           1,040\n",
      "         Linear-10              [1, 10]             170             170\n",
      "========================================================================\n",
      "Total params: 2,016,880\n",
      "Trainable params: 2,016,880\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 16.56 %\n",
      "Learning rate: 0.0000100000\n",
      "Epoch: 0............. Loss: 2.2380\n",
      "pk: 18.99 %\n",
      "Learning rate: 0.0000104000\n",
      "Epoch: 1............. Loss: 2.2947\n",
      "pk: 21.13 %\n",
      "Learning rate: 0.0000108160\n",
      "Epoch: 2............. Loss: 2.2199\n",
      "pk: 22.95 %\n",
      "Learning rate: 0.0000112486\n",
      "Epoch: 3............. Loss: 2.1886\n",
      "pk: 24.94 %\n",
      "Learning rate: 0.0000116986\n",
      "Epoch: 4............. Loss: 2.1716\n",
      "pk: 26.87 %\n",
      "Learning rate: 0.0000121665\n",
      "Epoch: 5............. Loss: 2.1558\n",
      "pk: 28.46 %\n",
      "Learning rate: 0.0000126532\n",
      "Epoch: 6............. Loss: 2.1583\n",
      "pk: 29.87 %\n",
      "Learning rate: 0.0000131593\n",
      "Epoch: 7............. Loss: 2.0502\n",
      "pk: 30.92 %\n",
      "Learning rate: 0.0000136857\n",
      "Epoch: 8............. Loss: 2.1161\n",
      "pk: 32.08 %\n",
      "Learning rate: 0.0000142331\n",
      "Epoch: 9............. Loss: 2.0761\n",
      "pk: 33.13 %\n",
      "Learning rate: 0.0000148024\n",
      "Epoch: 10............. Loss: 1.9866\n",
      "pk: 33.90 %\n",
      "Learning rate: 0.0000153945\n",
      "Epoch: 11............. Loss: 2.0493\n",
      "pk: 34.63 %\n",
      "Learning rate: 0.0000160103\n",
      "Epoch: 12............. Loss: 1.9946\n",
      "pk: 34.90 %\n",
      "Learning rate: 0.0000166507\n",
      "Epoch: 13............. Loss: 2.0032\n",
      "pk: 37.03 %\n",
      "Learning rate: 0.0000173168\n",
      "Epoch: 14............. Loss: 2.0020\n",
      "pk: 37.72 %\n",
      "Learning rate: 0.0000180094\n",
      "Epoch: 15............. Loss: 1.7934\n",
      "pk: 38.53 %\n",
      "Learning rate: 0.0000187298\n",
      "Epoch: 16............. Loss: 1.8783\n",
      "pk: 39.31 %\n",
      "Learning rate: 0.0000194790\n",
      "Epoch: 17............. Loss: 1.8729\n",
      "pk: 39.83 %\n",
      "Learning rate: 0.0000202582\n",
      "Epoch: 18............. Loss: 1.8349\n",
      "pk: 40.48 %\n",
      "Learning rate: 0.0000210685\n",
      "Epoch: 19............. Loss: 1.8249\n",
      "pk: 40.96 %\n",
      "Learning rate: 0.0000219112\n",
      "Epoch: 20............. Loss: 1.8627\n",
      "pk: 42.07 %\n",
      "Learning rate: 0.0000227877\n",
      "Epoch: 21............. Loss: 1.7532\n",
      "pk: 42.04 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 22............. Loss: 1.8160\n",
      "pk: 43.20 %\n",
      "Learning rate: 0.0000246472\n",
      "Epoch: 23............. Loss: 1.6856\n",
      "pk: 43.50 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 24............. Loss: 1.7317\n",
      "pk: 44.07 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 25............. Loss: 1.6536\n",
      "pk: 45.03 %\n",
      "Learning rate: 0.0000277247\n",
      "Epoch: 26............. Loss: 1.7269\n",
      "pk: 45.13 %\n",
      "Learning rate: 0.0000288337\n",
      "Epoch: 27............. Loss: 1.5040\n",
      "pk: 45.75 %\n",
      "Learning rate: 0.0000299870\n",
      "Epoch: 28............. Loss: 1.5799\n",
      "pk: 45.55 %\n",
      "Learning rate: 0.0000311865\n",
      "Epoch: 29............. Loss: 1.6670\n",
      "pk: 46.52 %\n",
      "Learning rate: 0.0000324340\n",
      "Epoch: 30............. Loss: 1.5273\n",
      "pk: 46.48 %\n",
      "Learning rate: 0.0000337313\n",
      "Epoch: 31............. Loss: 1.7198\n",
      "pk: 48.11 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 32............. Loss: 1.5994\n",
      "pk: 48.36 %\n",
      "Learning rate: 0.0000364838\n",
      "Epoch: 33............. Loss: 1.4904\n",
      "pk: 47.24 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 34............. Loss: 1.5643\n",
      "pk: 48.91 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 35............. Loss: 1.4508\n",
      "pk: 49.44 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 36............. Loss: 1.4986\n",
      "pk: 50.12 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 37............. Loss: 1.3584\n",
      "pk: 49.81 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 38............. Loss: 1.3633\n",
      "pk: 50.78 %\n",
      "Learning rate: 0.0000461637\n",
      "Epoch: 39............. Loss: 1.5711\n",
      "pk: 51.28 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 40............. Loss: 1.4263\n",
      "pk: 51.37 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 41............. Loss: 1.4297\n",
      "pk: 52.50 %\n",
      "Learning rate: 0.0000519278\n",
      "Epoch: 42............. Loss: 1.3324\n",
      "pk: 52.35 %\n",
      "Learning rate: 0.0000540050\n",
      "Epoch: 43............. Loss: 1.4646\n",
      "pk: 51.35 %\n",
      "Learning rate: 0.0000561652\n",
      "Epoch: 44............. Loss: 1.2713\n",
      "pk: 53.42 %\n",
      "Learning rate: 0.0000584118\n",
      "Epoch: 45............. Loss: 1.4799\n",
      "pk: 54.19 %\n",
      "Learning rate: 0.0000607482\n",
      "Epoch: 46............. Loss: 1.3865\n",
      "pk: 53.39 %\n",
      "Learning rate: 0.0000631782\n",
      "Epoch: 47............. Loss: 1.5062\n"
     ]
    }
   ],
   "source": [
    "# input image size in px (square image)\n",
    "input_size = 32\n",
    "dataset_name = \"cifar\"\n",
    "epoch = 200\n",
    "\n",
    "methods = ['kaiming_uniform']\n",
    "for method in methods:\n",
    "    for apt in range(3):\n",
    "        model = TrainModel(dataset=CifarDataset(), method=method, input_size=input_size,\n",
    "                                c_kernels=[3, 3, 3, 3, 3], in_channels=[3, 16, 32, 64, 86, 128], out_channels=[16, 32, 64, 86, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch, activation_relu=True)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \"shallow\" + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \"shallow\" + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + dataset_name + method + \"_\" + str(apt) + \"shallow\" + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + dataset_name + method + \"_\" + \"shallow\" + str(apt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 4\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 75, 75]               0               0\n",
      "          Conv2d-5       [1, 86, 75, 75]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 75, 75]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 37, 37]               0               0\n",
      "          Conv2d-8      [1, 128, 37, 37]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 37, 37]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 18, 18]               0               0\n",
      "         Conv2d-11      [1, 128, 18, 18]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 18, 18]         409,728         409,728\n",
      "      MaxPool2d-13        [1, 128, 9, 9]               0               0\n",
      "         Conv2d-14        [1, 128, 9, 9]         409,728         409,728\n",
      "         Conv2d-15        [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 4, 4]               0               0\n",
      "         Conv2d-17        [1, 128, 4, 4]         409,728         409,728\n",
      "         Linear-18              [1, 128]         262,272         262,272\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 3,812,780\n",
      "Trainable params: 3,812,780\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 58.07 %\n",
      "Learning rate: 0.0000100000\n",
      "Epoch: 0............. Loss: 1.0946\n",
      "pk: 62.10 %\n",
      "Learning rate: 0.0000104000\n",
      "Epoch: 1............. Loss: 0.9479\n",
      "pk: 65.07 %\n",
      "Learning rate: 0.0000108160\n",
      "Epoch: 2............. Loss: 0.9642\n",
      "pk: 66.33 %\n",
      "Learning rate: 0.0000112486\n",
      "Epoch: 3............. Loss: 1.0571\n",
      "pk: 68.17 %\n",
      "Learning rate: 0.0000116986\n",
      "Epoch: 4............. Loss: 0.8117\n",
      "pk: 70.57 %\n",
      "Learning rate: 0.0000121665\n",
      "Epoch: 5............. Loss: 0.8187\n",
      "pk: 69.40 %\n",
      "Learning rate: 0.0000126532\n",
      "Epoch: 6............. Loss: 0.8067\n",
      "pk: 72.47 %\n",
      "Learning rate: 0.0000131593\n",
      "Epoch: 7............. Loss: 0.8607\n",
      "pk: 73.37 %\n",
      "Learning rate: 0.0000136857\n",
      "Epoch: 8............. Loss: 0.7102\n",
      "pk: 75.27 %\n",
      "Learning rate: 0.0000142331\n",
      "Epoch: 9............. Loss: 0.7695\n",
      "pk: 75.97 %\n",
      "Learning rate: 0.0000148024\n",
      "Epoch: 10............. Loss: 0.7622\n",
      "pk: 77.43 %\n",
      "Learning rate: 0.0000153945\n",
      "Epoch: 11............. Loss: 0.6126\n",
      "pk: 78.97 %\n",
      "Learning rate: 0.0000160103\n",
      "Epoch: 12............. Loss: 0.8783\n",
      "pk: 78.23 %\n",
      "Learning rate: 0.0000166507\n",
      "Epoch: 13............. Loss: 0.8282\n",
      "pk: 75.70 %\n",
      "Learning rate: 0.0000173168\n",
      "Epoch: 14............. Loss: 0.7296\n",
      "pk: 77.53 %\n",
      "Learning rate: 0.0000180094\n",
      "Epoch: 15............. Loss: 0.5297\n",
      "pk: 78.53 %\n",
      "Learning rate: 0.0000187298\n",
      "Epoch: 16............. Loss: 0.8058\n",
      "pk: 81.03 %\n",
      "Learning rate: 0.0000194790\n",
      "Epoch: 17............. Loss: 0.6900\n",
      "pk: 78.30 %\n",
      "Learning rate: 0.0000202582\n",
      "Epoch: 18............. Loss: 0.5953\n",
      "pk: 79.80 %\n",
      "Learning rate: 0.0000210685\n",
      "Epoch: 19............. Loss: 0.3602\n",
      "pk: 77.60 %\n",
      "Learning rate: 0.0000219112\n",
      "Epoch: 20............. Loss: 0.5584\n",
      "pk: 81.60 %\n",
      "Learning rate: 0.0000227877\n",
      "Epoch: 21............. Loss: 0.4460\n",
      "pk: 80.07 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 22............. Loss: 0.4967\n",
      "pk: 82.30 %\n",
      "Learning rate: 0.0000246472\n",
      "Epoch: 23............. Loss: 0.5151\n",
      "pk: 81.53 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 24............. Loss: 0.4217\n",
      "pk: 80.87 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 25............. Loss: 0.2360\n",
      "pk: 82.40 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 26............. Loss: 0.4246\n",
      "pk: 82.73 %\n",
      "Learning rate: 0.0000277247\n",
      "Epoch: 27............. Loss: 0.9602\n",
      "pk: 82.30 %\n",
      "Learning rate: 0.0000288337\n",
      "Epoch: 28............. Loss: 0.2887\n",
      "pk: 81.70 %\n",
      "Learning rate: 0.0000299870\n",
      "Epoch: 29............. Loss: 0.4518\n",
      "pk: 82.83 %\n",
      "Learning rate: 0.0000311865\n",
      "Epoch: 30............. Loss: 0.5674\n",
      "pk: 83.27 %\n",
      "Learning rate: 0.0000324340\n",
      "Epoch: 31............. Loss: 0.3711\n",
      "pk: 82.73 %\n",
      "Learning rate: 0.0000337313\n",
      "Epoch: 32............. Loss: 0.5820\n",
      "pk: 81.27 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 33............. Loss: 0.1919\n",
      "pk: 81.00 %\n",
      "Learning rate: 0.0000364838\n",
      "Epoch: 34............. Loss: 0.5710\n",
      "pk: 81.37 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 35............. Loss: 0.2619\n",
      "pk: 79.83 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 36............. Loss: 0.3673\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 37............. Loss: 0.4049\n",
      "pk: 82.93 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 38............. Loss: 0.4449\n",
      "pk: 83.90 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 39............. Loss: 0.3072\n",
      "pk: 80.97 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 40............. Loss: 0.1472\n",
      "pk: 83.47 %\n",
      "Learning rate: 0.0000461637\n",
      "Epoch: 41............. Loss: 0.2559\n",
      "pk: 83.27 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 42............. Loss: 0.4200\n",
      "pk: 83.53 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 43............. Loss: 0.4593\n",
      "pk: 81.80 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 44............. Loss: 0.3243\n",
      "pk: 84.47 %\n",
      "Learning rate: 0.0000519278\n",
      "Epoch: 45............. Loss: 0.4429\n",
      "pk: 81.63 %\n",
      "Learning rate: 0.0000540050\n",
      "Epoch: 46............. Loss: 0.1915\n",
      "pk: 83.73 %\n",
      "Learning rate: 0.0000561652\n",
      "Epoch: 47............. Loss: 0.2892\n",
      "pk: 82.17 %\n",
      "Learning rate: 0.0000584118\n",
      "Epoch: 48............. Loss: 0.3007\n",
      "pk: 82.97 %\n",
      "Learning rate: 0.0000584118\n",
      "Epoch: 49............. Loss: 0.3608\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 4\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 75, 75]               0               0\n",
      "          Conv2d-5       [1, 86, 75, 75]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 75, 75]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 37, 37]               0               0\n",
      "          Conv2d-8      [1, 128, 37, 37]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 37, 37]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 18, 18]               0               0\n",
      "         Conv2d-11      [1, 128, 18, 18]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 18, 18]         409,728         409,728\n",
      "      MaxPool2d-13        [1, 128, 9, 9]               0               0\n",
      "         Conv2d-14        [1, 128, 9, 9]         409,728         409,728\n",
      "         Conv2d-15        [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 4, 4]               0               0\n",
      "         Conv2d-17        [1, 128, 4, 4]         409,728         409,728\n",
      "         Linear-18              [1, 128]         262,272         262,272\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 3,812,780\n",
      "Trainable params: 3,812,780\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 51.77 %\n",
      "Learning rate: 0.0000100000\n",
      "Epoch: 0............. Loss: 1.5404\n",
      "pk: 59.00 %\n",
      "Learning rate: 0.0000104000\n",
      "Epoch: 1............. Loss: 1.1827\n",
      "pk: 64.70 %\n",
      "Learning rate: 0.0000108160\n",
      "Epoch: 2............. Loss: 0.9865\n",
      "pk: 67.20 %\n",
      "Learning rate: 0.0000112486\n",
      "Epoch: 3............. Loss: 0.9026\n",
      "pk: 68.93 %\n",
      "Learning rate: 0.0000116986\n",
      "Epoch: 4............. Loss: 0.8190\n",
      "pk: 69.80 %\n",
      "Learning rate: 0.0000121665\n",
      "Epoch: 5............. Loss: 0.8190\n",
      "pk: 68.40 %\n",
      "Learning rate: 0.0000126532\n",
      "Epoch: 6............. Loss: 0.7165\n",
      "pk: 72.60 %\n",
      "Learning rate: 0.0000131593\n",
      "Epoch: 7............. Loss: 0.8022\n",
      "pk: 73.93 %\n",
      "Learning rate: 0.0000136857\n",
      "Epoch: 8............. Loss: 0.6415\n",
      "pk: 72.90 %\n",
      "Learning rate: 0.0000142331\n",
      "Epoch: 9............. Loss: 0.7377\n",
      "pk: 74.93 %\n",
      "Learning rate: 0.0000148024\n",
      "Epoch: 10............. Loss: 0.6827\n",
      "pk: 72.57 %\n",
      "Learning rate: 0.0000153945\n",
      "Epoch: 11............. Loss: 0.8126\n",
      "pk: 76.07 %\n",
      "Learning rate: 0.0000160103\n",
      "Epoch: 12............. Loss: 0.6916\n",
      "pk: 76.70 %\n",
      "Learning rate: 0.0000166507\n",
      "Epoch: 13............. Loss: 0.6196\n",
      "pk: 77.20 %\n",
      "Learning rate: 0.0000173168\n",
      "Epoch: 14............. Loss: 0.6275\n",
      "pk: 78.07 %\n",
      "Learning rate: 0.0000180094\n",
      "Epoch: 15............. Loss: 0.6982\n",
      "pk: 79.33 %\n",
      "Learning rate: 0.0000187298\n",
      "Epoch: 16............. Loss: 0.5691\n",
      "pk: 79.13 %\n",
      "Learning rate: 0.0000194790\n",
      "Epoch: 17............. Loss: 0.5869\n",
      "pk: 79.33 %\n",
      "Learning rate: 0.0000202582\n",
      "Epoch: 18............. Loss: 0.6057\n",
      "pk: 78.60 %\n",
      "Learning rate: 0.0000210685\n",
      "Epoch: 19............. Loss: 0.7528\n",
      "pk: 79.53 %\n",
      "Learning rate: 0.0000219112\n",
      "Epoch: 20............. Loss: 0.4707\n",
      "pk: 82.17 %\n",
      "Learning rate: 0.0000227877\n",
      "Epoch: 21............. Loss: 0.8001\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 22............. Loss: 0.4430\n",
      "pk: 81.60 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 23............. Loss: 0.4360\n",
      "pk: 80.63 %\n",
      "Learning rate: 0.0000246472\n",
      "Epoch: 24............. Loss: 0.5042\n",
      "pk: 80.00 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 25............. Loss: 0.5977\n",
      "pk: 82.40 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 26............. Loss: 0.3300\n",
      "pk: 82.37 %\n",
      "Learning rate: 0.0000277247\n",
      "Epoch: 27............. Loss: 0.5845\n",
      "pk: 82.53 %\n",
      "Learning rate: 0.0000288337\n",
      "Epoch: 28............. Loss: 0.5162\n",
      "pk: 80.37 %\n",
      "Learning rate: 0.0000299870\n",
      "Epoch: 29............. Loss: 0.5078\n",
      "pk: 77.60 %\n",
      "Learning rate: 0.0000311865\n",
      "Epoch: 30............. Loss: 0.4774\n",
      "pk: 82.33 %\n",
      "Learning rate: 0.0000324340\n",
      "Epoch: 31............. Loss: 0.4833\n",
      "pk: 82.93 %\n",
      "Learning rate: 0.0000337313\n",
      "Epoch: 32............. Loss: 0.3087\n",
      "pk: 82.97 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 33............. Loss: 0.3267\n",
      "pk: 81.33 %\n",
      "Learning rate: 0.0000364838\n",
      "Epoch: 34............. Loss: 0.4298\n",
      "pk: 80.70 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 35............. Loss: 0.2399\n",
      "pk: 82.70 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 36............. Loss: 0.5915\n",
      "pk: 83.13 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 37............. Loss: 0.4159\n",
      "pk: 82.23 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 38............. Loss: 0.3539\n",
      "pk: 82.67 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 39............. Loss: 0.1878\n",
      "pk: 82.90 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 40............. Loss: 0.4068\n",
      "pk: 80.30 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 41............. Loss: 0.3587\n",
      "pk: 83.10 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 42............. Loss: 0.2918\n",
      "pk: 80.10 %\n",
      "Learning rate: 0.0000461637\n",
      "Epoch: 43............. Loss: 0.4732\n",
      "pk: 81.20 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 44............. Loss: 0.2430\n",
      "pk: 83.87 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 45............. Loss: 0.3834\n",
      "pk: 81.23 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 46............. Loss: 0.2972\n",
      "pk: 83.07 %\n",
      "Learning rate: 0.0000519278\n",
      "Epoch: 47............. Loss: 0.2695\n",
      "pk: 83.83 %\n",
      "Learning rate: 0.0000540050\n",
      "Epoch: 48............. Loss: 0.1808\n",
      "pk: 82.63 %\n",
      "Learning rate: 0.0000561652\n",
      "Epoch: 49............. Loss: 0.3355\n",
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 4\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           2,368           2,368\n",
      "          Conv2d-2     [1, 32, 150, 150]          25,120          25,120\n",
      "          Conv2d-3     [1, 64, 150, 150]         100,416         100,416\n",
      "       MaxPool2d-4       [1, 64, 75, 75]               0               0\n",
      "          Conv2d-5       [1, 86, 75, 75]         269,782         269,782\n",
      "          Conv2d-6      [1, 128, 75, 75]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 37, 37]               0               0\n",
      "          Conv2d-8      [1, 128, 37, 37]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 37, 37]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 18, 18]               0               0\n",
      "         Conv2d-11      [1, 128, 18, 18]         409,728         409,728\n",
      "         Conv2d-12      [1, 128, 18, 18]         409,728         409,728\n",
      "      MaxPool2d-13        [1, 128, 9, 9]               0               0\n",
      "         Conv2d-14        [1, 128, 9, 9]         409,728         409,728\n",
      "         Conv2d-15        [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-16        [1, 128, 4, 4]               0               0\n",
      "         Conv2d-17        [1, 128, 4, 4]         409,728         409,728\n",
      "         Linear-18              [1, 128]         262,272         262,272\n",
      "         Linear-19               [1, 64]           8,256           8,256\n",
      "         Linear-20               [1, 16]           1,040           1,040\n",
      "         Linear-21                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 3,812,780\n",
      "Trainable params: 3,812,780\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 33.47 %\n",
      "Learning rate: 0.0000100000\n",
      "Epoch: 0............. Loss: 1.4079\n",
      "pk: 37.50 %\n",
      "Learning rate: 0.0000104000\n",
      "Epoch: 1............. Loss: 1.3902\n",
      "pk: 38.90 %\n",
      "Learning rate: 0.0000108160\n",
      "Epoch: 2............. Loss: 1.2476\n",
      "pk: 50.10 %\n",
      "Learning rate: 0.0000112486\n",
      "Epoch: 3............. Loss: 1.2971\n",
      "pk: 53.87 %\n",
      "Learning rate: 0.0000116986\n",
      "Epoch: 4............. Loss: 1.0883\n",
      "pk: 56.20 %\n",
      "Learning rate: 0.0000121665\n",
      "Epoch: 5............. Loss: 1.1039\n",
      "pk: 56.07 %\n",
      "Learning rate: 0.0000126532\n",
      "Epoch: 6............. Loss: 1.3402\n",
      "pk: 68.33 %\n",
      "Learning rate: 0.0000131593\n",
      "Epoch: 7............. Loss: 1.1515\n",
      "pk: 68.57 %\n",
      "Learning rate: 0.0000136857\n",
      "Epoch: 8............. Loss: 0.7674\n",
      "pk: 72.73 %\n",
      "Learning rate: 0.0000142331\n",
      "Epoch: 9............. Loss: 0.9123\n",
      "pk: 73.57 %\n",
      "Learning rate: 0.0000148024\n",
      "Epoch: 10............. Loss: 0.5455\n",
      "pk: 73.87 %\n",
      "Learning rate: 0.0000153945\n",
      "Epoch: 11............. Loss: 1.2700\n",
      "pk: 75.67 %\n",
      "Learning rate: 0.0000160103\n",
      "Epoch: 12............. Loss: 0.7065\n",
      "pk: 76.23 %\n",
      "Learning rate: 0.0000166507\n",
      "Epoch: 13............. Loss: 0.7682\n",
      "pk: 78.97 %\n",
      "Learning rate: 0.0000173168\n",
      "Epoch: 14............. Loss: 0.5703\n",
      "pk: 77.77 %\n",
      "Learning rate: 0.0000180094\n",
      "Epoch: 15............. Loss: 0.7868\n",
      "pk: 78.50 %\n",
      "Learning rate: 0.0000187298\n",
      "Epoch: 16............. Loss: 0.4448\n",
      "pk: 76.77 %\n",
      "Learning rate: 0.0000194790\n",
      "Epoch: 17............. Loss: 0.6895\n",
      "pk: 78.90 %\n",
      "Learning rate: 0.0000202582\n",
      "Epoch: 18............. Loss: 0.4915\n",
      "pk: 79.70 %\n",
      "Learning rate: 0.0000210685\n",
      "Epoch: 19............. Loss: 0.5525\n",
      "pk: 78.23 %\n",
      "Learning rate: 0.0000219112\n",
      "Epoch: 20............. Loss: 0.6592\n",
      "pk: 81.13 %\n",
      "Learning rate: 0.0000227877\n",
      "Epoch: 21............. Loss: 0.5106\n",
      "pk: 81.67 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 22............. Loss: 0.4061\n",
      "pk: 80.03 %\n",
      "Learning rate: 0.0000246472\n",
      "Epoch: 23............. Loss: 0.4690\n",
      "pk: 79.73 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 24............. Loss: 0.2604\n",
      "pk: 79.07 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 25............. Loss: 0.5861\n",
      "pk: 78.77 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 26............. Loss: 0.4883\n",
      "pk: 80.27 %\n",
      "Learning rate: 0.0000277247\n",
      "Epoch: 27............. Loss: 0.4022\n",
      "pk: 83.40 %\n",
      "Learning rate: 0.0000288337\n",
      "Epoch: 28............. Loss: 0.3699\n",
      "pk: 80.03 %\n",
      "Learning rate: 0.0000299870\n",
      "Epoch: 29............. Loss: 0.6223\n",
      "pk: 84.30 %\n",
      "Learning rate: 0.0000311865\n",
      "Epoch: 30............. Loss: 0.4885\n",
      "pk: 79.97 %\n",
      "Learning rate: 0.0000324340\n",
      "Epoch: 31............. Loss: 0.5612\n",
      "pk: 83.90 %\n",
      "Learning rate: 0.0000337313\n",
      "Epoch: 32............. Loss: 0.4657\n",
      "pk: 83.80 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 33............. Loss: 0.5693\n",
      "pk: 85.10 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 34............. Loss: 0.3633\n",
      "pk: 82.50 %\n",
      "Learning rate: 0.0000364838\n",
      "Epoch: 35............. Loss: 0.2762\n",
      "pk: 83.83 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 36............. Loss: 0.4051\n",
      "pk: 80.83 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 37............. Loss: 0.3517\n",
      "pk: 83.63 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 38............. Loss: 0.3920\n",
      "pk: 84.50 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 39............. Loss: 0.5489\n",
      "pk: 84.47 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 40............. Loss: 0.7004\n",
      "pk: 81.37 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 41............. Loss: 0.3773\n",
      "pk: 84.17 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 42............. Loss: 0.2876\n",
      "pk: 83.93 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 43............. Loss: 0.2164\n",
      "pk: 81.93 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 44............. Loss: 0.2712\n",
      "pk: 84.47 %\n",
      "Learning rate: 0.0000461637\n",
      "Epoch: 45............. Loss: 0.3140\n",
      "pk: 83.53 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 46............. Loss: 0.3724\n",
      "pk: 83.73 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 47............. Loss: 0.4697\n",
      "pk: 83.27 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 48............. Loss: 0.4517\n",
      "pk: 81.83 %\n",
      "Learning rate: 0.0000519278\n",
      "Epoch: 49............. Loss: 0.2259\n"
     ]
    }
   ],
   "source": [
    "input_size = 150\n",
    "epoch = 50\n",
    "dataset_name = \"intel\"\n",
    "methods = ['kaiming_uniform']\n",
    "\n",
    "for method in methods:\n",
    "    for apt in range(3, 6):\n",
    "        model = TrainModel(dataset=IntelDataset(), method=method, input_size=input_size,\n",
    "                            c_kernels=[7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch, padding_flag=True, maxpool_freq=2, activation_relu=True, fc_size=4)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + method + \"_\" + str(apt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']\n",
      "class num: 6\n",
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 18\n",
      "-------------------------------------------------------------------------\n",
      "      Layer (type)          Output Shape         Param #     Tr. Param #\n",
      "=========================================================================\n",
      "          Conv2d-1     [1, 16, 150, 150]           1,216           1,216\n",
      "          Conv2d-2     [1, 32, 150, 150]          12,832          12,832\n",
      "          Conv2d-3     [1, 64, 150, 150]          51,264          51,264\n",
      "       MaxPool2d-4       [1, 64, 75, 75]               0               0\n",
      "          Conv2d-5       [1, 86, 75, 75]         137,686         137,686\n",
      "          Conv2d-6      [1, 128, 75, 75]         275,328         275,328\n",
      "       MaxPool2d-7      [1, 128, 37, 37]               0               0\n",
      "          Conv2d-8      [1, 128, 37, 37]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 37, 37]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 18, 18]               0               0\n",
      "         Linear-11              [1, 128]       5,308,544       5,308,544\n",
      "         Linear-12               [1, 64]           8,256           8,256\n",
      "         Linear-13               [1, 16]           1,040           1,040\n",
      "         Linear-14                [1, 6]             102             102\n",
      "=========================================================================\n",
      "Total params: 6,615,724\n",
      "Trainable params: 6,615,724\n",
      "Non-trainable params: 0\n",
      "-------------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 17.50 %\n",
      "Learning rate: 0.0000100000\n",
      "Epoch: 0............. Loss: 1.7503\n",
      "pk: 24.77 %\n",
      "Learning rate: 0.0000104000\n",
      "Epoch: 1............. Loss: 1.6971\n",
      "pk: 27.90 %\n",
      "Learning rate: 0.0000108160\n",
      "Epoch: 2............. Loss: 1.6085\n",
      "pk: 28.10 %\n",
      "Learning rate: 0.0000112486\n",
      "Epoch: 3............. Loss: 1.6372\n",
      "pk: 30.40 %\n",
      "Learning rate: 0.0000116986\n",
      "Epoch: 4............. Loss: 1.5534\n",
      "pk: 32.20 %\n",
      "Learning rate: 0.0000121665\n",
      "Epoch: 5............. Loss: 1.5037\n",
      "pk: 37.13 %\n",
      "Learning rate: 0.0000126532\n",
      "Epoch: 6............. Loss: 1.5010\n",
      "pk: 37.73 %\n",
      "Learning rate: 0.0000131593\n",
      "Epoch: 7............. Loss: 1.5791\n",
      "pk: 40.20 %\n",
      "Learning rate: 0.0000136857\n",
      "Epoch: 8............. Loss: 1.5159\n",
      "pk: 42.43 %\n",
      "Learning rate: 0.0000142331\n",
      "Epoch: 9............. Loss: 1.3463\n",
      "pk: 47.60 %\n",
      "Learning rate: 0.0000148024\n",
      "Epoch: 10............. Loss: 1.3277\n",
      "pk: 54.17 %\n",
      "Learning rate: 0.0000153945\n",
      "Epoch: 11............. Loss: 1.4271\n",
      "pk: 56.40 %\n",
      "Learning rate: 0.0000160103\n",
      "Epoch: 12............. Loss: 1.2387\n",
      "pk: 57.63 %\n",
      "Learning rate: 0.0000166507\n",
      "Epoch: 13............. Loss: 1.2106\n",
      "pk: 58.17 %\n",
      "Learning rate: 0.0000173168\n",
      "Epoch: 14............. Loss: 1.0936\n",
      "pk: 59.50 %\n",
      "Learning rate: 0.0000180094\n",
      "Epoch: 15............. Loss: 1.3070\n",
      "pk: 61.20 %\n",
      "Learning rate: 0.0000187298\n",
      "Epoch: 16............. Loss: 1.0368\n",
      "pk: 60.27 %\n",
      "Learning rate: 0.0000194790\n",
      "Epoch: 17............. Loss: 1.4564\n",
      "pk: 62.30 %\n",
      "Learning rate: 0.0000202582\n",
      "Epoch: 18............. Loss: 1.1561\n",
      "pk: 62.80 %\n",
      "Learning rate: 0.0000210685\n",
      "Epoch: 19............. Loss: 0.9120\n",
      "pk: 62.53 %\n",
      "Learning rate: 0.0000219112\n",
      "Epoch: 20............. Loss: 1.4715\n",
      "pk: 62.03 %\n",
      "Learning rate: 0.0000227877\n",
      "Epoch: 21............. Loss: 1.2163\n",
      "pk: 64.53 %\n",
      "Learning rate: 0.0000236992\n",
      "Epoch: 22............. Loss: 1.1413\n",
      "pk: 61.20 %\n",
      "Learning rate: 0.0000246472\n",
      "Epoch: 23............. Loss: 0.9070\n",
      "pk: 65.50 %\n",
      "Learning rate: 0.0000256330\n",
      "Epoch: 24............. Loss: 0.9873\n",
      "pk: 64.93 %\n",
      "Learning rate: 0.0000266584\n",
      "Epoch: 25............. Loss: 1.3661\n",
      "pk: 65.33 %\n",
      "Learning rate: 0.0000277247\n",
      "Epoch: 26............. Loss: 0.9043\n",
      "pk: 66.97 %\n",
      "Learning rate: 0.0000288337\n",
      "Epoch: 27............. Loss: 0.7954\n",
      "pk: 65.73 %\n",
      "Learning rate: 0.0000299870\n",
      "Epoch: 28............. Loss: 0.8200\n",
      "pk: 65.90 %\n",
      "Learning rate: 0.0000311865\n",
      "Epoch: 29............. Loss: 0.5838\n",
      "pk: 68.80 %\n",
      "Learning rate: 0.0000324340\n",
      "Epoch: 30............. Loss: 0.8047\n",
      "pk: 65.67 %\n",
      "Learning rate: 0.0000337313\n",
      "Epoch: 31............. Loss: 1.0152\n",
      "pk: 69.60 %\n",
      "Learning rate: 0.0000350806\n",
      "Epoch: 32............. Loss: 0.7574\n",
      "pk: 69.00 %\n",
      "Learning rate: 0.0000364838\n",
      "Epoch: 33............. Loss: 0.6411\n",
      "pk: 71.40 %\n",
      "Learning rate: 0.0000379432\n",
      "Epoch: 34............. Loss: 0.8113\n",
      "pk: 69.87 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 35............. Loss: 0.8389\n",
      "pk: 70.20 %\n",
      "Learning rate: 0.0000394609\n",
      "Epoch: 36............. Loss: 0.8554\n",
      "pk: 70.20 %\n",
      "Learning rate: 0.0000410393\n",
      "Epoch: 37............. Loss: 0.9151\n",
      "pk: 71.93 %\n",
      "Learning rate: 0.0000426809\n",
      "Epoch: 38............. Loss: 0.7734\n",
      "pk: 72.20 %\n",
      "Learning rate: 0.0000443881\n",
      "Epoch: 39............. Loss: 0.5968\n",
      "pk: 72.93 %\n",
      "Learning rate: 0.0000461637\n",
      "Epoch: 40............. Loss: 0.5959\n",
      "pk: 74.10 %\n",
      "Learning rate: 0.0000480102\n",
      "Epoch: 41............. Loss: 0.7613\n",
      "pk: 72.83 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 42............. Loss: 0.9035\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0000499306\n",
      "Epoch: 43............. Loss: 0.7764\n",
      "pk: 73.13 %\n",
      "Learning rate: 0.0000519278\n",
      "Epoch: 44............. Loss: 0.5838\n",
      "pk: 74.57 %\n",
      "Learning rate: 0.0000540050\n",
      "Epoch: 45............. Loss: 0.9050\n",
      "pk: 73.30 %\n",
      "Learning rate: 0.0000561652\n",
      "Epoch: 46............. Loss: 0.7619\n",
      "pk: 73.07 %\n",
      "Learning rate: 0.0000584118\n",
      "Epoch: 47............. Loss: 0.5995\n",
      "pk: 76.30 %\n",
      "Learning rate: 0.0000607482\n",
      "Epoch: 48............. Loss: 0.5667\n",
      "pk: 75.43 %\n",
      "Learning rate: 0.0000631782\n",
      "Epoch: 49............. Loss: 0.8859\n",
      "pk: 76.47 %\n",
      "Learning rate: 0.0000657053\n",
      "Epoch: 50............. Loss: 1.2499\n",
      "pk: 74.47 %\n",
      "Learning rate: 0.0000683335\n",
      "Epoch: 51............. Loss: 0.7882\n",
      "pk: 72.73 %\n",
      "Learning rate: 0.0000710668\n",
      "Epoch: 52............. Loss: 0.5804\n",
      "pk: 76.40 %\n",
      "Learning rate: 0.0000739095\n",
      "Epoch: 53............. Loss: 0.6127\n",
      "pk: 76.53 %\n",
      "Learning rate: 0.0000739095\n",
      "Epoch: 54............. Loss: 0.9536\n",
      "pk: 74.70 %\n",
      "Learning rate: 0.0000768659\n",
      "Epoch: 55............. Loss: 0.8306\n",
      "pk: 77.60 %\n",
      "Learning rate: 0.0000799405\n",
      "Epoch: 56............. Loss: 0.7057\n",
      "pk: 76.13 %\n",
      "Learning rate: 0.0000831381\n",
      "Epoch: 57............. Loss: 0.5688\n",
      "pk: 79.47 %\n",
      "Learning rate: 0.0000831381\n",
      "Epoch: 58............. Loss: 0.6974\n",
      "pk: 78.63 %\n",
      "Learning rate: 0.0000864637\n",
      "Epoch: 59............. Loss: 0.4213\n",
      "pk: 78.23 %\n",
      "Learning rate: 0.0000899222\n",
      "Epoch: 60............. Loss: 0.3907\n",
      "pk: 79.77 %\n",
      "Learning rate: 0.0000935191\n",
      "Epoch: 61............. Loss: 0.3978\n",
      "pk: 79.30 %\n",
      "Learning rate: 0.0000972599\n",
      "Epoch: 62............. Loss: 0.5647\n",
      "pk: 79.57 %\n",
      "Learning rate: 0.0001011503\n",
      "Epoch: 63............. Loss: 0.3572\n",
      "pk: 79.90 %\n",
      "Learning rate: 0.0001051963\n",
      "Epoch: 64............. Loss: 0.3074\n",
      "pk: 78.27 %\n",
      "Learning rate: 0.0001051963\n",
      "Epoch: 65............. Loss: 0.5184\n",
      "pk: 80.10 %\n",
      "Learning rate: 0.0001094041\n",
      "Epoch: 66............. Loss: 0.3135\n",
      "pk: 78.20 %\n",
      "Learning rate: 0.0001137803\n",
      "Epoch: 67............. Loss: 0.6023\n",
      "pk: 80.27 %\n",
      "Learning rate: 0.0001183315\n",
      "Epoch: 68............. Loss: 0.3761\n",
      "pk: 79.03 %\n",
      "Learning rate: 0.0001230648\n",
      "Epoch: 69............. Loss: 0.5357\n",
      "pk: 80.77 %\n",
      "Learning rate: 0.0001279874\n",
      "Epoch: 70............. Loss: 0.6195\n",
      "pk: 80.43 %\n",
      "Learning rate: 0.0001331068\n",
      "Epoch: 71............. Loss: 0.1736\n",
      "pk: 79.33 %\n",
      "Learning rate: 0.0001384311\n",
      "Epoch: 72............. Loss: 0.4518\n",
      "pk: 79.47 %\n",
      "Learning rate: 0.0001439684\n",
      "Epoch: 73............. Loss: 0.7208\n",
      "pk: 81.43 %\n",
      "Learning rate: 0.0001439684\n",
      "Epoch: 74............. Loss: 0.4608\n",
      "pk: 81.87 %\n",
      "Learning rate: 0.0001497271\n",
      "Epoch: 75............. Loss: 0.7035\n",
      "pk: 81.27 %\n",
      "Learning rate: 0.0001557162\n",
      "Epoch: 76............. Loss: 0.5899\n",
      "pk: 82.10 %\n",
      "Learning rate: 0.0001619448\n",
      "Epoch: 77............. Loss: 0.2874\n",
      "pk: 81.70 %\n",
      "Learning rate: 0.0001684226\n",
      "Epoch: 78............. Loss: 0.4181\n",
      "pk: 82.07 %\n",
      "Learning rate: 0.0001751595\n",
      "Epoch: 79............. Loss: 0.2161\n",
      "pk: 82.03 %\n",
      "Learning rate: 0.0001821659\n",
      "Epoch: 80............. Loss: 0.5634\n",
      "pk: 81.60 %\n",
      "Learning rate: 0.0001894525\n",
      "Epoch: 81............. Loss: 0.2899\n",
      "pk: 82.40 %\n",
      "Learning rate: 0.0001970306\n",
      "Epoch: 82............. Loss: 0.2047\n",
      "pk: 82.87 %\n",
      "Learning rate: 0.0002049119\n",
      "Epoch: 83............. Loss: 0.2434\n",
      "pk: 78.80 %\n",
      "Learning rate: 0.0002131083\n",
      "Epoch: 84............. Loss: 0.1761\n",
      "pk: 78.93 %\n",
      "Learning rate: 0.0002216327\n",
      "Epoch: 85............. Loss: 0.3832\n",
      "pk: 81.03 %\n",
      "Learning rate: 0.0002216327\n",
      "Epoch: 86............. Loss: 0.4300\n",
      "pk: 81.03 %\n",
      "Learning rate: 0.0002304980\n",
      "Epoch: 87............. Loss: 0.2478\n",
      "pk: 80.07 %\n",
      "Learning rate: 0.0002304980\n",
      "Epoch: 88............. Loss: 0.0891\n",
      "pk: 81.50 %\n",
      "Learning rate: 0.0002397179\n",
      "Epoch: 89............. Loss: 0.1267\n",
      "pk: 79.80 %\n",
      "Learning rate: 0.0002493066\n",
      "Epoch: 90............. Loss: 0.1731\n",
      "pk: 80.77 %\n",
      "Learning rate: 0.0002592789\n",
      "Epoch: 91............. Loss: 0.0463\n",
      "pk: 79.30 %\n",
      "Learning rate: 0.0002696500\n",
      "Epoch: 92............. Loss: 0.2805\n",
      "pk: 80.27 %\n",
      "Learning rate: 0.0002804360\n",
      "Epoch: 93............. Loss: 0.1671\n",
      "pk: 79.37 %\n",
      "Learning rate: 0.0002916535\n",
      "Epoch: 94............. Loss: 0.2072\n",
      "pk: 81.53 %\n",
      "Learning rate: 0.0002916535\n",
      "Epoch: 95............. Loss: 0.1562\n",
      "pk: 79.47 %\n",
      "Learning rate: 0.0003033196\n",
      "Epoch: 96............. Loss: 0.1184\n",
      "pk: 80.87 %\n",
      "Learning rate: 0.0003154524\n",
      "Epoch: 97............. Loss: 0.1403\n",
      "pk: 81.43 %\n",
      "Learning rate: 0.0003154524\n",
      "Epoch: 98............. Loss: 0.2571\n",
      "pk: 80.30 %\n",
      "Learning rate: 0.0003280705\n",
      "Epoch: 99............. Loss: 0.0947\n",
      "pk: 80.07 %\n",
      "Learning rate: 0.0003411933\n",
      "Epoch: 100............. Loss: 0.0558\n",
      "pk: 81.17 %\n",
      "Learning rate: 0.0003548411\n",
      "Epoch: 101............. Loss: 0.2371\n",
      "pk: 80.33 %\n",
      "Learning rate: 0.0003548411\n",
      "Epoch: 102............. Loss: 0.0398\n",
      "pk: 80.87 %\n",
      "Learning rate: 0.0003690347\n",
      "Epoch: 103............. Loss: 0.1560\n",
      "pk: 80.13 %\n",
      "Learning rate: 0.0003690347\n",
      "Epoch: 104............. Loss: 0.0246\n",
      "pk: 80.70 %\n",
      "Learning rate: 0.0003837961\n",
      "Epoch: 105............. Loss: 0.0166\n",
      "pk: 79.80 %\n",
      "Learning rate: 0.0003991479\n",
      "Epoch: 106............. Loss: 0.0351\n",
      "pk: 79.10 %\n",
      "Learning rate: 0.0004151139\n",
      "Epoch: 107............. Loss: 0.0244\n",
      "pk: 81.60 %\n",
      "Learning rate: 0.0004151139\n",
      "Epoch: 108............. Loss: 0.0461\n",
      "pk: 78.27 %\n",
      "Learning rate: 0.0004317184\n",
      "Epoch: 109............. Loss: 0.2927\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0004489872\n",
      "Epoch: 110............. Loss: 0.1200\n",
      "pk: 80.50 %\n",
      "Learning rate: 0.0004489872\n",
      "Epoch: 111............. Loss: 0.0601\n",
      "pk: 79.93 %\n",
      "Learning rate: 0.0004669466\n",
      "Epoch: 112............. Loss: 0.1031\n",
      "pk: 79.63 %\n",
      "Learning rate: 0.0004669466\n",
      "Epoch: 113............. Loss: 0.0557\n",
      "pk: 80.63 %\n",
      "Learning rate: 0.0004856245\n",
      "Epoch: 114............. Loss: 0.0310\n",
      "pk: 78.57 %\n",
      "Learning rate: 0.0005050495\n",
      "Epoch: 115............. Loss: 0.0533\n",
      "pk: 77.63 %\n",
      "Learning rate: 0.0005252515\n",
      "Epoch: 116............. Loss: 0.0055\n",
      "pk: 79.83 %\n",
      "Learning rate: 0.0005252515\n",
      "Epoch: 117............. Loss: 0.0350\n",
      "pk: 81.00 %\n",
      "Learning rate: 0.0005462615\n",
      "Epoch: 118............. Loss: 0.0148\n",
      "pk: 80.47 %\n",
      "Learning rate: 0.0005681120\n",
      "Epoch: 119............. Loss: 0.1720\n",
      "pk: 79.17 %\n",
      "Learning rate: 0.0005681120\n",
      "Epoch: 120............. Loss: 0.0321\n",
      "pk: 79.67 %\n",
      "Learning rate: 0.0005681120\n",
      "Epoch: 121............. Loss: 0.0217\n",
      "pk: 80.30 %\n",
      "Learning rate: 0.0005908365\n",
      "Epoch: 122............. Loss: 0.0123\n",
      "pk: 80.83 %\n",
      "Learning rate: 0.0006144699\n",
      "Epoch: 123............. Loss: 0.0921\n",
      "pk: 81.77 %\n",
      "Learning rate: 0.0006390487\n",
      "Epoch: 124............. Loss: 0.0098\n",
      "pk: 80.17 %\n",
      "Learning rate: 0.0006390487\n",
      "Epoch: 125............. Loss: 0.0131\n",
      "pk: 80.97 %\n",
      "Learning rate: 0.0006390487\n",
      "Epoch: 126............. Loss: 0.0451\n",
      "pk: 80.70 %\n",
      "Learning rate: 0.0006646107\n",
      "Epoch: 127............. Loss: 0.0356\n",
      "pk: 78.77 %\n",
      "Learning rate: 0.0006646107\n",
      "Epoch: 128............. Loss: 0.0298\n",
      "pk: 78.13 %\n",
      "Learning rate: 0.0006911951\n",
      "Epoch: 129............. Loss: 0.0091\n",
      "pk: 78.67 %\n",
      "Learning rate: 0.0006911951\n",
      "Epoch: 130............. Loss: 0.0158\n",
      "pk: 81.30 %\n",
      "Learning rate: 0.0006911951\n",
      "Epoch: 131............. Loss: 0.0067\n",
      "pk: 80.90 %\n",
      "Learning rate: 0.0007188429\n",
      "Epoch: 132............. Loss: 0.0123\n",
      "pk: 81.20 %\n",
      "Learning rate: 0.0007475966\n",
      "Epoch: 133............. Loss: 0.0012\n",
      "pk: 81.27 %\n",
      "Learning rate: 0.0007475966\n",
      "Epoch: 134............. Loss: 0.0365\n",
      "pk: 80.90 %\n",
      "Learning rate: 0.0007775005\n",
      "Epoch: 135............. Loss: 0.0045\n",
      "pk: 80.80 %\n",
      "Learning rate: 0.0007775005\n",
      "Epoch: 136............. Loss: 0.0027\n",
      "pk: 81.67 %\n",
      "Learning rate: 0.0008086005\n",
      "Epoch: 137............. Loss: 0.2601\n",
      "pk: 81.50 %\n",
      "Learning rate: 0.0008086005\n",
      "Epoch: 138............. Loss: 0.0968\n",
      "pk: 80.20 %\n",
      "Learning rate: 0.0008409445\n",
      "Epoch: 139............. Loss: 0.0524\n",
      "pk: 80.47 %\n",
      "Learning rate: 0.0008745823\n",
      "Epoch: 140............. Loss: 0.0103\n",
      "pk: 78.90 %\n",
      "Learning rate: 0.0009095656\n",
      "Epoch: 141............. Loss: 0.0152\n",
      "pk: 80.67 %\n",
      "Learning rate: 0.0009095656\n",
      "Epoch: 142............. Loss: 0.0017\n",
      "pk: 80.83 %\n",
      "Learning rate: 0.0009095656\n",
      "Epoch: 143............. Loss: 0.0239\n",
      "pk: 81.30 %\n",
      "Learning rate: 0.0009459482\n",
      "Epoch: 144............. Loss: 0.0697\n",
      "pk: 81.20 %\n",
      "Learning rate: 0.0009459482\n",
      "Epoch: 145............. Loss: 0.0013\n",
      "pk: 79.30 %\n",
      "Learning rate: 0.0009459482\n",
      "Epoch: 146............. Loss: 0.0694\n",
      "pk: 80.73 %\n",
      "Learning rate: 0.0009837861\n",
      "Epoch: 147............. Loss: 0.0461\n",
      "pk: 80.33 %\n",
      "Learning rate: 0.0010231376\n",
      "Epoch: 148............. Loss: 0.0182\n",
      "pk: 80.03 %\n",
      "Learning rate: 0.0010231376\n",
      "Epoch: 149............. Loss: 0.0028\n",
      "pk: 79.43 %\n",
      "Learning rate: 0.0010231376\n",
      "Epoch: 150............. Loss: 0.0501\n",
      "pk: 81.03 %\n",
      "Learning rate: 0.0010640631\n",
      "Epoch: 151............. Loss: 0.0225\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0011066256\n",
      "Epoch: 152............. Loss: 0.0005\n",
      "pk: 80.07 %\n",
      "Learning rate: 0.0011066256\n",
      "Epoch: 153............. Loss: 0.0256\n",
      "pk: 81.30 %\n",
      "Learning rate: 0.0011066256\n",
      "Epoch: 154............. Loss: 0.0061\n",
      "pk: 78.60 %\n",
      "Learning rate: 0.0011508906\n",
      "Epoch: 155............. Loss: 0.0578\n",
      "pk: 79.33 %\n",
      "Learning rate: 0.0011508906\n",
      "Epoch: 156............. Loss: 0.0581\n",
      "pk: 80.23 %\n",
      "Learning rate: 0.0011969263\n",
      "Epoch: 157............. Loss: 0.0148\n",
      "pk: 78.80 %\n",
      "Learning rate: 0.0011969263\n",
      "Epoch: 158............. Loss: 0.0068\n",
      "pk: 79.27 %\n",
      "Learning rate: 0.0012448033\n",
      "Epoch: 159............. Loss: 0.0100\n",
      "pk: 80.03 %\n",
      "Learning rate: 0.0012945954\n",
      "Epoch: 160............. Loss: 0.0147\n",
      "pk: 76.13 %\n",
      "Learning rate: 0.0012945954\n",
      "Epoch: 161............. Loss: 0.1064\n",
      "pk: 79.83 %\n",
      "Learning rate: 0.0012945954\n",
      "Epoch: 162............. Loss: 0.0017\n",
      "pk: 80.47 %\n",
      "Learning rate: 0.0013463793\n",
      "Epoch: 163............. Loss: 0.0251\n",
      "pk: 79.80 %\n",
      "Learning rate: 0.0013463793\n",
      "Epoch: 164............. Loss: 0.2611\n",
      "pk: 80.53 %\n",
      "Learning rate: 0.0014002344\n",
      "Epoch: 165............. Loss: 0.0031\n",
      "pk: 79.70 %\n",
      "Learning rate: 0.0014002344\n",
      "Epoch: 166............. Loss: 0.0573\n",
      "pk: 79.37 %\n",
      "Learning rate: 0.0014002344\n",
      "Epoch: 167............. Loss: 0.0018\n",
      "pk: 80.10 %\n",
      "Learning rate: 0.0014562438\n",
      "Epoch: 168............. Loss: 0.0293\n",
      "pk: 80.13 %\n",
      "Learning rate: 0.0015144936\n",
      "Epoch: 169............. Loss: 0.0154\n",
      "pk: 79.90 %\n",
      "Learning rate: 0.0015144936\n",
      "Epoch: 170............. Loss: 0.1059\n",
      "pk: 79.73 %\n",
      "Learning rate: 0.0015750733\n",
      "Epoch: 171............. Loss: 0.0129\n",
      "pk: 81.77 %\n",
      "Learning rate: 0.0016380762\n",
      "Epoch: 172............. Loss: 0.0178\n",
      "pk: 79.97 %\n",
      "Learning rate: 0.0016380762\n",
      "Epoch: 173............. Loss: 0.0177\n",
      "pk: 81.33 %\n",
      "Learning rate: 0.0017035993\n",
      "Epoch: 174............. Loss: 0.0541\n",
      "pk: 79.97 %\n",
      "Learning rate: 0.0017717433\n",
      "Epoch: 175............. Loss: 0.0039\n",
      "pk: 77.93 %\n",
      "Learning rate: 0.0017717433\n",
      "Epoch: 176............. Loss: 0.0100\n",
      "pk: 81.23 %\n",
      "Learning rate: 0.0017717433\n",
      "Epoch: 177............. Loss: 0.0024\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0018426130\n",
      "Epoch: 178............. Loss: 0.0262\n",
      "pk: 79.77 %\n",
      "Learning rate: 0.0018426130\n",
      "Epoch: 179............. Loss: 0.0015\n",
      "pk: 80.07 %\n",
      "Learning rate: 0.0019163175\n",
      "Epoch: 180............. Loss: 0.0044\n",
      "pk: 81.57 %\n",
      "Learning rate: 0.0019163175\n",
      "Epoch: 181............. Loss: 0.0961\n",
      "pk: 78.73 %\n",
      "Learning rate: 0.0019929702\n",
      "Epoch: 182............. Loss: 0.0993\n",
      "pk: 80.77 %\n",
      "Learning rate: 0.0019929702\n",
      "Epoch: 183............. Loss: 0.0313\n",
      "pk: 80.27 %\n",
      "Learning rate: 0.0019929702\n",
      "Epoch: 184............. Loss: 0.0016\n",
      "pk: 80.53 %\n",
      "Learning rate: 0.0020726890\n",
      "Epoch: 185............. Loss: 0.0007\n",
      "pk: 77.30 %\n",
      "Learning rate: 0.0020726890\n",
      "Epoch: 186............. Loss: 0.0540\n",
      "pk: 79.80 %\n",
      "Learning rate: 0.0021555966\n",
      "Epoch: 187............. Loss: 0.0303\n",
      "pk: 79.77 %\n",
      "Learning rate: 0.0021555966\n",
      "Epoch: 188............. Loss: 0.0334\n",
      "pk: 79.67 %\n",
      "Learning rate: 0.0021555966\n",
      "Epoch: 189............. Loss: 0.0846\n",
      "pk: 79.47 %\n",
      "Learning rate: 0.0021555966\n",
      "Epoch: 190............. Loss: 0.2362\n",
      "pk: 78.67 %\n",
      "Learning rate: 0.0022418204\n",
      "Epoch: 191............. Loss: 0.0044\n",
      "pk: 80.73 %\n",
      "Learning rate: 0.0023314933\n",
      "Epoch: 192............. Loss: 0.0079\n",
      "pk: 80.33 %\n",
      "Learning rate: 0.0023314933\n",
      "Epoch: 193............. Loss: 0.0297\n",
      "pk: 81.30 %\n",
      "Learning rate: 0.0023314933\n",
      "Epoch: 194............. Loss: 0.0036\n",
      "pk: 81.10 %\n",
      "Learning rate: 0.0024247530\n",
      "Epoch: 195............. Loss: 0.0008\n",
      "pk: 78.80 %\n",
      "Learning rate: 0.0024247530\n",
      "Epoch: 196............. Loss: 0.0084\n",
      "pk: 81.73 %\n",
      "Learning rate: 0.0024247530\n",
      "Epoch: 197............. Loss: 0.0073\n",
      "pk: 80.40 %\n",
      "Learning rate: 0.0025217431\n",
      "Epoch: 198............. Loss: 0.0789\n",
      "pk: 81.03 %\n",
      "Learning rate: 0.0025217431\n",
      "Epoch: 199............. Loss: 0.0008\n"
     ]
    }
   ],
   "source": [
    "input_size = 150\n",
    "epoch = 200\n",
    "dataset_name = \"intel\"\n",
    "methods = ['kaiming_uniform']\n",
    "\n",
    "for method in methods:\n",
    "    for apt in range(5, 6):\n",
    "        model = TrainModel(dataset=IntelDataset(), method=method, input_size=input_size,\n",
    "                            c_kernels=[5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch, padding_flag=True, maxpool_freq=2, activation_relu=True, fc_size=4)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \"shallow\" + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + \"_\" + str(apt) + \"shallow\" + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + \"_\" + str(apt) + \"shallow\" + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + method + \"_\" + \"shallow\" + str(apt))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
