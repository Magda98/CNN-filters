{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from CifarDataset import CifarDataset\n",
    "from IntelDataset import IntelDataset\n",
    "from TrainModel import TrainModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 14.90 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 2.2494\n",
      "pk: 27.99 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.9675\n",
      "pk: 36.89 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.7346\n",
      "pk: 41.32 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.6411\n",
      "pk: 45.98 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.5605\n",
      "pk: 50.90 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 1.5520\n",
      "pk: 54.40 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 1.2015\n",
      "pk: 55.02 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 1.2797\n",
      "pk: 60.53 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.1960\n",
      "pk: 62.71 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 1.1001\n",
      "pk: 65.41 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.8385\n",
      "pk: 67.09 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.8180\n",
      "pk: 68.52 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.9232\n",
      "pk: 69.87 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.9574\n",
      "pk: 69.01 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 1.0265\n",
      "pk: 71.17 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.8926\n",
      "pk: 71.91 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.9061\n",
      "pk: 73.03 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 17............. Loss: 0.8303\n",
      "pk: 73.40 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 18............. Loss: 0.7723\n",
      "pk: 72.84 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 19............. Loss: 0.6699\n",
      "pk: 74.00 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 20............. Loss: 0.5438\n",
      "pk: 73.24 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 21............. Loss: 0.7176\n",
      "pk: 74.54 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 22............. Loss: 0.5796\n",
      "pk: 74.53 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 23............. Loss: 0.5350\n",
      "pk: 73.98 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 24............. Loss: 0.6724\n",
      "pk: 75.74 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 25............. Loss: 0.6658\n",
      "pk: 75.45 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 26............. Loss: 0.5821\n",
      "pk: 74.21 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 27............. Loss: 0.7640\n",
      "pk: 74.90 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 28............. Loss: 0.6715\n",
      "pk: 74.37 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 29............. Loss: 0.5263\n",
      "pk: 76.01 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 30............. Loss: 0.3714\n",
      "pk: 76.25 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 31............. Loss: 0.4426\n",
      "pk: 75.39 %\n",
      "Learning rate: 0.0035080587\n",
      "Epoch: 32............. Loss: 0.5571\n",
      "pk: 75.89 %\n",
      "Learning rate: 0.0036483811\n",
      "Epoch: 33............. Loss: 0.4257\n",
      "pk: 76.27 %\n",
      "Learning rate: 0.0037943163\n",
      "Epoch: 34............. Loss: 0.4110\n",
      "pk: 75.86 %\n",
      "Learning rate: 0.0039460890\n",
      "Epoch: 35............. Loss: 0.2836\n",
      "pk: 76.33 %\n",
      "Learning rate: 0.0041039326\n",
      "Epoch: 36............. Loss: 0.5476\n",
      "pk: 75.79 %\n",
      "Learning rate: 0.0042680899\n",
      "Epoch: 37............. Loss: 0.3937\n",
      "pk: 76.39 %\n",
      "Learning rate: 0.0044388135\n",
      "Epoch: 38............. Loss: 0.5196\n",
      "pk: 74.78 %\n",
      "Learning rate: 0.0044388135\n",
      "Epoch: 39............. Loss: 0.3721\n",
      "pk: 75.90 %\n",
      "Learning rate: 0.0046163660\n",
      "Epoch: 40............. Loss: 0.3262\n",
      "pk: 75.27 %\n",
      "Learning rate: 0.0048010206\n",
      "Epoch: 41............. Loss: 0.4579\n",
      "pk: 75.86 %\n",
      "Learning rate: 0.0049930615\n",
      "Epoch: 42............. Loss: 0.4351\n",
      "pk: 75.50 %\n",
      "Learning rate: 0.0051927839\n",
      "Epoch: 43............. Loss: 0.3477\n",
      "pk: 75.28 %\n",
      "Learning rate: 0.0054004953\n",
      "Epoch: 44............. Loss: 0.4239\n",
      "pk: 75.42 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 45............. Loss: 0.3077\n",
      "pk: 76.30 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 46............. Loss: 0.3198\n",
      "pk: 75.37 %\n",
      "Learning rate: 0.0058411757\n",
      "Epoch: 47............. Loss: 0.2852\n",
      "pk: 75.68 %\n",
      "Learning rate: 0.0060748227\n",
      "Epoch: 48............. Loss: 0.3108\n",
      "pk: 75.65 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 49............. Loss: 0.3105\n",
      "pk: 75.52 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 50............. Loss: 0.5428\n",
      "pk: 75.43 %\n",
      "Learning rate: 0.0065705282\n",
      "Epoch: 51............. Loss: 0.3082\n",
      "pk: 76.19 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 52............. Loss: 0.4761\n",
      "pk: 75.88 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 53............. Loss: 0.3057\n",
      "pk: 76.06 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 54............. Loss: 0.2946\n",
      "pk: 75.20 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 55............. Loss: 0.4179\n",
      "pk: 74.90 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 56............. Loss: 0.3243\n",
      "pk: 74.92 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 57............. Loss: 0.2576\n",
      "pk: 75.45 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 58............. Loss: 0.3116\n",
      "pk: 76.20 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 59............. Loss: 0.2275\n",
      "pk: 75.64 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 60............. Loss: 0.4214\n",
      "pk: 74.50 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 61............. Loss: 0.4003\n",
      "pk: 75.82 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 62............. Loss: 0.1938\n",
      "pk: 74.62 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 63............. Loss: 0.3699\n",
      "pk: 75.67 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 64............. Loss: 0.2205\n",
      "pk: 75.73 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 65............. Loss: 0.2739\n",
      "pk: 75.84 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 66............. Loss: 0.3307\n",
      "pk: 74.52 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 67............. Loss: 0.2721\n",
      "pk: 74.25 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 68............. Loss: 0.3108\n",
      "pk: 74.13 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 69............. Loss: 0.3862\n",
      "pk: 74.88 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 70............. Loss: 0.2615\n",
      "pk: 74.24 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 71............. Loss: 0.2548\n",
      "pk: 74.89 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 72............. Loss: 0.1897\n",
      "pk: 74.54 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 73............. Loss: 0.3686\n",
      "pk: 74.72 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 74............. Loss: 0.3292\n",
      "pk: 74.84 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 75............. Loss: 0.3223\n",
      "pk: 74.93 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 76............. Loss: 0.2850\n",
      "pk: 74.96 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 77............. Loss: 0.3961\n",
      "pk: 74.36 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 78............. Loss: 0.2003\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 79............. Loss: 0.2898\n",
      "pk: 74.03 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 80............. Loss: 0.4533\n",
      "pk: 74.55 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 81............. Loss: 0.4257\n",
      "pk: 74.87 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 82............. Loss: 0.3505\n",
      "pk: 72.70 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 83............. Loss: 0.4107\n",
      "pk: 74.63 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 84............. Loss: 0.5028\n",
      "pk: 73.29 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 85............. Loss: 0.5226\n",
      "pk: 74.01 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 86............. Loss: 0.5960\n",
      "pk: 74.24 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 87............. Loss: 0.4285\n",
      "pk: 74.42 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 88............. Loss: 0.4012\n",
      "pk: 74.22 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 89............. Loss: 0.4726\n",
      "pk: 72.97 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 90............. Loss: 0.3664\n",
      "pk: 74.20 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 91............. Loss: 0.3945\n",
      "pk: 73.93 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 92............. Loss: 0.3602\n",
      "pk: 74.50 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 93............. Loss: 0.5117\n",
      "pk: 74.10 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 94............. Loss: 0.4724\n",
      "pk: 74.10 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 95............. Loss: 0.4826\n",
      "pk: 74.66 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 96............. Loss: 0.5013\n",
      "pk: 74.77 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 97............. Loss: 0.3964\n",
      "pk: 73.47 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 98............. Loss: 0.4491\n",
      "pk: 74.21 %\n",
      "Learning rate: 0.0143968365\n",
      "Epoch: 99............. Loss: 0.4430\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 18.71 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 2.2229\n",
      "pk: 26.30 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.9316\n",
      "pk: 33.85 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.8850\n",
      "pk: 38.18 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.7174\n",
      "pk: 41.59 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.5527\n",
      "pk: 48.15 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 1.4747\n",
      "pk: 51.66 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 1.4971\n",
      "pk: 53.99 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 1.2499\n",
      "pk: 57.01 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.1383\n",
      "pk: 60.76 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 1.1142\n",
      "pk: 64.28 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 1.1302\n",
      "pk: 63.90 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 1.2687\n",
      "pk: 66.53 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.9099\n",
      "pk: 66.73 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.8389\n",
      "pk: 69.79 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 1.0618\n",
      "pk: 70.48 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.7685\n",
      "pk: 69.78 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.7915\n",
      "pk: 72.11 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 17............. Loss: 0.8528\n",
      "pk: 72.43 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 18............. Loss: 0.6811\n",
      "pk: 73.73 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 19............. Loss: 0.6742\n",
      "pk: 71.94 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 20............. Loss: 0.7182\n",
      "pk: 72.66 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 21............. Loss: 0.7836\n",
      "pk: 73.18 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 22............. Loss: 0.5439\n",
      "pk: 74.10 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 23............. Loss: 0.7394\n",
      "pk: 74.36 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 24............. Loss: 0.8109\n",
      "pk: 74.90 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 25............. Loss: 0.6132\n",
      "pk: 74.55 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 26............. Loss: 0.5833\n",
      "pk: 74.38 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 27............. Loss: 0.5409\n",
      "pk: 74.71 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 28............. Loss: 0.5988\n",
      "pk: 76.08 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 29............. Loss: 0.5983\n",
      "pk: 74.67 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 30............. Loss: 0.5161\n",
      "pk: 74.19 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 31............. Loss: 0.3931\n",
      "pk: 74.98 %\n",
      "Learning rate: 0.0035080587\n",
      "Epoch: 32............. Loss: 0.4926\n",
      "pk: 76.42 %\n",
      "Learning rate: 0.0036483811\n",
      "Epoch: 33............. Loss: 0.4553\n",
      "pk: 75.74 %\n",
      "Learning rate: 0.0037943163\n",
      "Epoch: 34............. Loss: 0.4886\n",
      "pk: 76.16 %\n",
      "Learning rate: 0.0039460890\n",
      "Epoch: 35............. Loss: 0.3757\n",
      "pk: 75.32 %\n",
      "Learning rate: 0.0041039326\n",
      "Epoch: 36............. Loss: 0.5565\n",
      "pk: 75.64 %\n",
      "Learning rate: 0.0042680899\n",
      "Epoch: 37............. Loss: 0.3736\n",
      "pk: 75.74 %\n",
      "Learning rate: 0.0044388135\n",
      "Epoch: 38............. Loss: 0.5320\n",
      "pk: 74.81 %\n",
      "Learning rate: 0.0046163660\n",
      "Epoch: 39............. Loss: 0.3410\n",
      "pk: 74.96 %\n",
      "Learning rate: 0.0048010206\n",
      "Epoch: 40............. Loss: 0.2815\n",
      "pk: 75.98 %\n",
      "Learning rate: 0.0049930615\n",
      "Epoch: 41............. Loss: 0.4580\n",
      "pk: 75.88 %\n",
      "Learning rate: 0.0051927839\n",
      "Epoch: 42............. Loss: 0.5445\n",
      "pk: 75.88 %\n",
      "Learning rate: 0.0054004953\n",
      "Epoch: 43............. Loss: 0.3384\n",
      "pk: 75.34 %\n",
      "Learning rate: 0.0054004953\n",
      "Epoch: 44............. Loss: 0.3421\n",
      "pk: 75.96 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 45............. Loss: 0.3004\n",
      "pk: 76.09 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 46............. Loss: 0.2664\n",
      "pk: 74.97 %\n",
      "Learning rate: 0.0058411757\n",
      "Epoch: 47............. Loss: 0.3454\n",
      "pk: 74.96 %\n",
      "Learning rate: 0.0060748227\n",
      "Epoch: 48............. Loss: 0.2581\n",
      "pk: 73.27 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 49............. Loss: 0.4558\n",
      "pk: 75.37 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 50............. Loss: 0.3276\n",
      "pk: 75.58 %\n",
      "Learning rate: 0.0065705282\n",
      "Epoch: 51............. Loss: 0.2876\n",
      "pk: 75.07 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 52............. Loss: 0.2569\n",
      "pk: 74.36 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 53............. Loss: 0.2854\n",
      "pk: 75.56 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 54............. Loss: 0.3069\n",
      "pk: 75.14 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 55............. Loss: 0.3503\n",
      "pk: 73.32 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 56............. Loss: 0.3934\n",
      "pk: 74.95 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 57............. Loss: 0.2800\n",
      "pk: 74.51 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 58............. Loss: 0.3748\n",
      "pk: 74.51 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 59............. Loss: 0.3401\n",
      "pk: 74.48 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 60............. Loss: 0.1684\n",
      "pk: 74.82 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 61............. Loss: 0.2675\n",
      "pk: 74.89 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 62............. Loss: 0.3665\n",
      "pk: 75.03 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 63............. Loss: 0.4743\n",
      "pk: 75.72 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 64............. Loss: 0.2998\n",
      "pk: 74.90 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 65............. Loss: 0.2013\n",
      "pk: 75.35 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 66............. Loss: 0.3142\n",
      "pk: 74.60 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 67............. Loss: 0.2762\n",
      "pk: 73.96 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 68............. Loss: 0.4100\n",
      "pk: 75.14 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 69............. Loss: 0.3654\n",
      "pk: 74.07 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 70............. Loss: 0.4943\n",
      "pk: 75.29 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 71............. Loss: 0.4115\n",
      "pk: 73.47 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 72............. Loss: 0.2723\n",
      "pk: 74.90 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 73............. Loss: 0.3383\n",
      "pk: 73.60 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 74............. Loss: 0.4901\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 75............. Loss: 0.3109\n",
      "pk: 74.22 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 76............. Loss: 0.4905\n",
      "pk: 73.96 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 77............. Loss: 0.3701\n",
      "pk: 73.68 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 78............. Loss: 0.3978\n",
      "pk: 73.03 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 79............. Loss: 0.4921\n",
      "pk: 72.90 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 80............. Loss: 0.3124\n",
      "pk: 74.33 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 81............. Loss: 0.4840\n",
      "pk: 73.63 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 82............. Loss: 0.4873\n",
      "pk: 72.69 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 83............. Loss: 0.4784\n",
      "pk: 73.38 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 84............. Loss: 0.4158\n",
      "pk: 73.92 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 85............. Loss: 0.2284\n",
      "pk: 73.67 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 86............. Loss: 0.6029\n",
      "pk: 73.62 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 87............. Loss: 0.3963\n",
      "pk: 73.11 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 88............. Loss: 0.4236\n",
      "pk: 74.11 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 89............. Loss: 0.4712\n",
      "pk: 74.31 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 90............. Loss: 0.3557\n",
      "pk: 73.19 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 91............. Loss: 0.3969\n",
      "pk: 73.24 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 92............. Loss: 0.4979\n",
      "pk: 73.20 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 93............. Loss: 0.4703\n",
      "pk: 73.40 %\n",
      "Learning rate: 0.0143968365\n",
      "Epoch: 94............. Loss: 0.4206\n",
      "pk: 73.82 %\n",
      "Learning rate: 0.0143968365\n",
      "Epoch: 95............. Loss: 0.5065\n",
      "pk: 73.95 %\n",
      "Learning rate: 0.0149727100\n",
      "Epoch: 96............. Loss: 0.3445\n",
      "pk: 73.77 %\n",
      "Learning rate: 0.0149727100\n",
      "Epoch: 97............. Loss: 0.5809\n",
      "pk: 73.10 %\n",
      "Learning rate: 0.0149727100\n",
      "Epoch: 98............. Loss: 0.5432\n",
      "pk: 72.58 %\n",
      "Learning rate: 0.0149727100\n",
      "Epoch: 99............. Loss: 0.4335\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 18.22 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 2.2160\n",
      "pk: 23.76 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 2.0686\n",
      "pk: 35.31 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.8994\n",
      "pk: 42.10 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.5900\n",
      "pk: 45.57 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.4544\n",
      "pk: 49.77 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 1.5861\n",
      "pk: 54.81 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 1.1600\n",
      "pk: 56.92 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 1.2215\n",
      "pk: 59.72 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.2977\n",
      "pk: 61.51 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 1.2512\n",
      "pk: 64.44 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.9851\n",
      "pk: 66.51 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 1.0252\n",
      "pk: 66.88 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.9818\n",
      "pk: 68.51 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.9133\n",
      "pk: 67.80 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 1.0098\n",
      "pk: 70.91 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.6834\n",
      "pk: 71.50 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.6490\n",
      "pk: 72.54 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 17............. Loss: 0.8153\n",
      "pk: 72.56 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 18............. Loss: 0.8426\n",
      "pk: 74.19 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 19............. Loss: 0.6280\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 20............. Loss: 0.6588\n",
      "pk: 72.26 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 21............. Loss: 0.7312\n",
      "pk: 74.74 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 22............. Loss: 0.5956\n",
      "pk: 74.61 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 23............. Loss: 0.6494\n",
      "pk: 74.63 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 24............. Loss: 0.6108\n",
      "pk: 75.35 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 25............. Loss: 0.4997\n",
      "pk: 74.70 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 26............. Loss: 0.6145\n",
      "pk: 75.16 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 27............. Loss: 0.4841\n",
      "pk: 75.01 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 28............. Loss: 0.5561\n",
      "pk: 75.33 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 29............. Loss: 0.4292\n",
      "pk: 75.68 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 30............. Loss: 0.5110\n",
      "pk: 75.64 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 31............. Loss: 0.4553\n",
      "pk: 75.40 %\n",
      "Learning rate: 0.0035080587\n",
      "Epoch: 32............. Loss: 0.3741\n",
      "pk: 76.17 %\n",
      "Learning rate: 0.0036483811\n",
      "Epoch: 33............. Loss: 0.5031\n",
      "pk: 76.11 %\n",
      "Learning rate: 0.0037943163\n",
      "Epoch: 34............. Loss: 0.4914\n",
      "pk: 75.90 %\n",
      "Learning rate: 0.0039460890\n",
      "Epoch: 35............. Loss: 0.2655\n",
      "pk: 76.53 %\n",
      "Learning rate: 0.0041039326\n",
      "Epoch: 36............. Loss: 0.3898\n",
      "pk: 75.79 %\n",
      "Learning rate: 0.0042680899\n",
      "Epoch: 37............. Loss: 0.5229\n",
      "pk: 76.30 %\n",
      "Learning rate: 0.0044388135\n",
      "Epoch: 38............. Loss: 0.5616\n",
      "pk: 75.68 %\n",
      "Learning rate: 0.0046163660\n",
      "Epoch: 39............. Loss: 0.4443\n",
      "pk: 76.39 %\n",
      "Learning rate: 0.0048010206\n",
      "Epoch: 40............. Loss: 0.6261\n",
      "pk: 76.24 %\n",
      "Learning rate: 0.0048010206\n",
      "Epoch: 41............. Loss: 0.2119\n",
      "pk: 75.44 %\n",
      "Learning rate: 0.0049930615\n",
      "Epoch: 42............. Loss: 0.2838\n",
      "pk: 76.68 %\n",
      "Learning rate: 0.0051927839\n",
      "Epoch: 43............. Loss: 0.2332\n",
      "pk: 75.31 %\n",
      "Learning rate: 0.0051927839\n",
      "Epoch: 44............. Loss: 0.4048\n",
      "pk: 76.21 %\n",
      "Learning rate: 0.0054004953\n",
      "Epoch: 45............. Loss: 0.2835\n",
      "pk: 76.50 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 46............. Loss: 0.3159\n",
      "pk: 76.03 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 47............. Loss: 0.2522\n",
      "pk: 75.37 %\n",
      "Learning rate: 0.0058411757\n",
      "Epoch: 48............. Loss: 0.2639\n",
      "pk: 75.21 %\n",
      "Learning rate: 0.0058411757\n",
      "Epoch: 49............. Loss: 0.3805\n",
      "pk: 75.06 %\n",
      "Learning rate: 0.0060748227\n",
      "Epoch: 50............. Loss: 0.1652\n",
      "pk: 75.73 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 51............. Loss: 0.3268\n",
      "pk: 75.87 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 52............. Loss: 0.2894\n",
      "pk: 75.55 %\n",
      "Learning rate: 0.0065705282\n",
      "Epoch: 53............. Loss: 0.2862\n",
      "pk: 75.69 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 54............. Loss: 0.3605\n",
      "pk: 76.04 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 55............. Loss: 0.1532\n",
      "pk: 76.09 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 56............. Loss: 0.2369\n",
      "pk: 75.50 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 57............. Loss: 0.2601\n",
      "pk: 75.12 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 58............. Loss: 0.3040\n",
      "pk: 76.03 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 59............. Loss: 0.2072\n",
      "pk: 75.48 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 60............. Loss: 0.3792\n",
      "pk: 75.26 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 61............. Loss: 0.3693\n",
      "pk: 75.30 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 62............. Loss: 0.2757\n",
      "pk: 75.58 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 63............. Loss: 0.2598\n",
      "pk: 76.09 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 64............. Loss: 0.2474\n",
      "pk: 75.91 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 65............. Loss: 0.2599\n",
      "pk: 75.12 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 66............. Loss: 0.3650\n",
      "pk: 75.69 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 67............. Loss: 0.2659\n",
      "pk: 74.93 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 68............. Loss: 0.2634\n",
      "pk: 75.70 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 69............. Loss: 0.3835\n",
      "pk: 75.47 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 70............. Loss: 0.4186\n",
      "pk: 74.87 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 71............. Loss: 0.2270\n",
      "pk: 74.57 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 72............. Loss: 0.3848\n",
      "pk: 74.34 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 73............. Loss: 0.1568\n",
      "pk: 76.16 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 74............. Loss: 0.2735\n",
      "pk: 75.73 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 75............. Loss: 0.2851\n",
      "pk: 73.23 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 76............. Loss: 0.4308\n",
      "pk: 74.38 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 77............. Loss: 0.1960\n",
      "pk: 73.97 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 78............. Loss: 0.3809\n",
      "pk: 74.63 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 79............. Loss: 0.2789\n",
      "pk: 75.54 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 80............. Loss: 0.3326\n",
      "pk: 74.05 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 81............. Loss: 0.3495\n",
      "pk: 75.19 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 82............. Loss: 0.3525\n",
      "pk: 74.34 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 83............. Loss: 0.4248\n",
      "pk: 74.63 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 84............. Loss: 0.4938\n",
      "pk: 74.92 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 85............. Loss: 0.5167\n",
      "pk: 74.60 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 86............. Loss: 0.2503\n",
      "pk: 73.85 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 87............. Loss: 0.3694\n",
      "pk: 74.23 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 88............. Loss: 0.2455\n",
      "pk: 75.12 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 89............. Loss: 0.3554\n",
      "pk: 74.14 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 90............. Loss: 0.4109\n",
      "pk: 75.14 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 91............. Loss: 0.1721\n",
      "pk: 74.67 %\n",
      "Learning rate: 0.0127987352\n",
      "Epoch: 92............. Loss: 0.3502\n",
      "pk: 74.10 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 93............. Loss: 0.3767\n",
      "pk: 74.16 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 94............. Loss: 0.5138\n",
      "pk: 74.21 %\n",
      "Learning rate: 0.0133106846\n",
      "Epoch: 95............. Loss: 0.4876\n",
      "pk: 73.83 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 96............. Loss: 0.4672\n",
      "pk: 73.75 %\n",
      "Learning rate: 0.0138431120\n",
      "Epoch: 97............. Loss: 0.4954\n",
      "pk: 73.66 %\n",
      "Learning rate: 0.0143968365\n",
      "Epoch: 98............. Loss: 0.3037\n",
      "pk: 73.63 %\n",
      "Learning rate: 0.0143968365\n",
      "Epoch: 99............. Loss: 0.4564\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 29.28 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 2.0649\n",
      "pk: 39.53 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.5526\n",
      "pk: 46.04 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.4293\n",
      "pk: 49.84 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.3676\n",
      "pk: 56.27 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.3084\n",
      "pk: 60.68 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 1.0139\n",
      "pk: 62.47 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 1.2724\n",
      "pk: 63.99 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.9107\n",
      "pk: 65.61 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.0464\n",
      "pk: 68.79 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.9813\n",
      "pk: 67.55 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.7646\n",
      "pk: 70.45 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.8456\n",
      "pk: 70.80 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.6746\n",
      "pk: 71.05 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.8089\n",
      "pk: 72.46 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 0.5290\n",
      "pk: 72.95 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.7703\n",
      "pk: 73.62 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.6650\n",
      "pk: 71.58 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 17............. Loss: 0.5817\n",
      "pk: 73.78 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 18............. Loss: 0.5840\n",
      "pk: 73.06 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 19............. Loss: 0.5384\n",
      "pk: 74.27 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 20............. Loss: 0.4775\n",
      "pk: 72.96 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 21............. Loss: 0.4862\n",
      "pk: 74.12 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 22............. Loss: 0.5083\n",
      "pk: 72.62 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 23............. Loss: 0.5977\n",
      "pk: 72.79 %\n",
      "Learning rate: 0.0025633042\n",
      "Epoch: 24............. Loss: 0.5160\n",
      "pk: 73.47 %\n",
      "Learning rate: 0.0026658363\n",
      "Epoch: 25............. Loss: 0.5366\n",
      "pk: 74.76 %\n",
      "Learning rate: 0.0027724698\n",
      "Epoch: 26............. Loss: 0.3761\n",
      "pk: 75.10 %\n",
      "Learning rate: 0.0028833686\n",
      "Epoch: 27............. Loss: 0.4655\n",
      "pk: 73.40 %\n",
      "Learning rate: 0.0029987033\n",
      "Epoch: 28............. Loss: 0.4921\n",
      "pk: 73.73 %\n",
      "Learning rate: 0.0031186515\n",
      "Epoch: 29............. Loss: 0.3698\n",
      "pk: 74.72 %\n",
      "Learning rate: 0.0032433975\n",
      "Epoch: 30............. Loss: 0.4606\n",
      "pk: 74.18 %\n",
      "Learning rate: 0.0033731334\n",
      "Epoch: 31............. Loss: 0.3463\n",
      "pk: 73.41 %\n",
      "Learning rate: 0.0035080587\n",
      "Epoch: 32............. Loss: 0.4143\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0036483811\n",
      "Epoch: 33............. Loss: 0.3794\n",
      "pk: 73.87 %\n",
      "Learning rate: 0.0037943163\n",
      "Epoch: 34............. Loss: 0.3978\n",
      "pk: 73.70 %\n",
      "Learning rate: 0.0039460890\n",
      "Epoch: 35............. Loss: 0.3727\n",
      "pk: 73.30 %\n",
      "Learning rate: 0.0041039326\n",
      "Epoch: 36............. Loss: 0.3409\n",
      "pk: 73.70 %\n",
      "Learning rate: 0.0042680899\n",
      "Epoch: 37............. Loss: 0.5691\n",
      "pk: 74.20 %\n",
      "Learning rate: 0.0042680899\n",
      "Epoch: 38............. Loss: 0.2839\n",
      "pk: 74.92 %\n",
      "Learning rate: 0.0044388135\n",
      "Epoch: 39............. Loss: 0.2864\n",
      "pk: 74.95 %\n",
      "Learning rate: 0.0044388135\n",
      "Epoch: 40............. Loss: 0.4970\n",
      "pk: 74.62 %\n",
      "Learning rate: 0.0046163660\n",
      "Epoch: 41............. Loss: 0.2643\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0048010206\n",
      "Epoch: 42............. Loss: 0.3472\n",
      "pk: 73.66 %\n",
      "Learning rate: 0.0048010206\n",
      "Epoch: 43............. Loss: 0.3065\n",
      "pk: 74.04 %\n",
      "Learning rate: 0.0049930615\n",
      "Epoch: 44............. Loss: 0.2813\n",
      "pk: 74.64 %\n",
      "Learning rate: 0.0051927839\n",
      "Epoch: 45............. Loss: 0.2058\n",
      "pk: 71.93 %\n",
      "Learning rate: 0.0051927839\n",
      "Epoch: 46............. Loss: 0.4305\n",
      "pk: 73.61 %\n",
      "Learning rate: 0.0054004953\n",
      "Epoch: 47............. Loss: 0.3176\n",
      "pk: 74.36 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 48............. Loss: 0.2239\n",
      "pk: 73.98 %\n",
      "Learning rate: 0.0056165151\n",
      "Epoch: 49............. Loss: 0.3007\n",
      "pk: 74.59 %\n",
      "Learning rate: 0.0058411757\n",
      "Epoch: 50............. Loss: 0.3075\n",
      "pk: 73.60 %\n",
      "Learning rate: 0.0058411757\n",
      "Epoch: 51............. Loss: 0.3018\n",
      "pk: 72.76 %\n",
      "Learning rate: 0.0060748227\n",
      "Epoch: 52............. Loss: 0.4657\n",
      "pk: 71.31 %\n",
      "Learning rate: 0.0060748227\n",
      "Epoch: 53............. Loss: 0.2064\n",
      "pk: 74.45 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 54............. Loss: 0.2419\n",
      "pk: 73.88 %\n",
      "Learning rate: 0.0063178156\n",
      "Epoch: 55............. Loss: 0.2520\n",
      "pk: 73.35 %\n",
      "Learning rate: 0.0065705282\n",
      "Epoch: 56............. Loss: 0.3475\n",
      "pk: 74.25 %\n",
      "Learning rate: 0.0065705282\n",
      "Epoch: 57............. Loss: 0.3324\n",
      "pk: 73.18 %\n",
      "Learning rate: 0.0065705282\n",
      "Epoch: 58............. Loss: 0.2174\n",
      "pk: 74.14 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 59............. Loss: 0.3798\n",
      "pk: 74.30 %\n",
      "Learning rate: 0.0068333494\n",
      "Epoch: 60............. Loss: 0.1723\n",
      "pk: 73.53 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 61............. Loss: 0.3824\n",
      "pk: 74.54 %\n",
      "Learning rate: 0.0071066833\n",
      "Epoch: 62............. Loss: 0.3116\n",
      "pk: 73.92 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 63............. Loss: 0.2974\n",
      "pk: 73.52 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 64............. Loss: 0.3038\n",
      "pk: 73.58 %\n",
      "Learning rate: 0.0073909507\n",
      "Epoch: 65............. Loss: 0.2449\n",
      "pk: 72.69 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 66............. Loss: 0.3766\n",
      "pk: 73.68 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 67............. Loss: 0.4756\n",
      "pk: 74.34 %\n",
      "Learning rate: 0.0076865887\n",
      "Epoch: 68............. Loss: 0.2466\n",
      "pk: 74.42 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 69............. Loss: 0.2898\n",
      "pk: 74.69 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 70............. Loss: 0.1988\n",
      "pk: 74.43 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 71............. Loss: 0.3589\n",
      "pk: 73.55 %\n",
      "Learning rate: 0.0079940523\n",
      "Epoch: 72............. Loss: 0.2429\n",
      "pk: 73.97 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 73............. Loss: 0.2390\n",
      "pk: 72.53 %\n",
      "Learning rate: 0.0083138143\n",
      "Epoch: 74............. Loss: 0.3573\n",
      "pk: 73.00 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 75............. Loss: 0.3613\n",
      "pk: 73.09 %\n",
      "Learning rate: 0.0086463669\n",
      "Epoch: 76............. Loss: 0.3321\n",
      "pk: 73.99 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 77............. Loss: 0.4700\n",
      "pk: 73.47 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 78............. Loss: 0.5694\n",
      "pk: 73.00 %\n",
      "Learning rate: 0.0089922216\n",
      "Epoch: 79............. Loss: 0.4501\n",
      "pk: 74.29 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 80............. Loss: 0.3261\n",
      "pk: 73.33 %\n",
      "Learning rate: 0.0093519105\n",
      "Epoch: 81............. Loss: 0.3029\n",
      "pk: 73.82 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 82............. Loss: 0.3019\n",
      "pk: 73.87 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 83............. Loss: 0.2773\n",
      "pk: 74.06 %\n",
      "Learning rate: 0.0097259869\n",
      "Epoch: 84............. Loss: 0.3304\n",
      "pk: 72.30 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 85............. Loss: 0.4401\n",
      "pk: 73.69 %\n",
      "Learning rate: 0.0101150264\n",
      "Epoch: 86............. Loss: 0.3509\n",
      "pk: 74.01 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 87............. Loss: 0.3531\n",
      "pk: 73.52 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 88............. Loss: 0.4064\n",
      "pk: 73.74 %\n",
      "Learning rate: 0.0105196274\n",
      "Epoch: 89............. Loss: 0.4057\n",
      "pk: 71.93 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 90............. Loss: 0.4139\n",
      "pk: 73.16 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 91............. Loss: 0.6518\n",
      "pk: 73.77 %\n",
      "Learning rate: 0.0109404125\n",
      "Epoch: 92............. Loss: 0.4267\n",
      "pk: 72.27 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 93............. Loss: 0.4149\n",
      "pk: 73.91 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 94............. Loss: 0.4503\n",
      "pk: 73.03 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 95............. Loss: 0.3859\n",
      "pk: 73.25 %\n",
      "Learning rate: 0.0113780290\n",
      "Epoch: 96............. Loss: 0.4660\n",
      "pk: 72.01 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 97............. Loss: 0.6346\n",
      "pk: 74.17 %\n",
      "Learning rate: 0.0118331502\n",
      "Epoch: 98............. Loss: 0.3893\n",
      "pk: 73.82 %\n",
      "Learning rate: 0.0123064762\n",
      "Epoch: 99............. Loss: 0.3855\n",
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "class num: 10\n",
      "ilość klas: 10\n",
      "wielkość po warstawach conv: 5\n",
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 16, 32, 32]           1,216           1,216\n",
      "       MaxPool2d-2     [1, 16, 17, 17]               0               0\n",
      "          Conv2d-3     [1, 32, 17, 17]          12,832          12,832\n",
      "          Conv2d-4     [1, 64, 17, 17]          51,264          51,264\n",
      "          Conv2d-5     [1, 86, 17, 17]         137,686         137,686\n",
      "       MaxPool2d-6       [1, 86, 9, 9]               0               0\n",
      "          Conv2d-7      [1, 128, 9, 9]         275,328         275,328\n",
      "          Conv2d-8      [1, 128, 9, 9]         409,728         409,728\n",
      "          Conv2d-9      [1, 128, 9, 9]         409,728         409,728\n",
      "      MaxPool2d-10      [1, 128, 5, 5]               0               0\n",
      "         Conv2d-11      [1, 128, 5, 5]         409,728         409,728\n",
      "         Linear-12             [1, 64]         204,864         204,864\n",
      "         Linear-13             [1, 16]           1,040           1,040\n",
      "         Linear-14             [1, 10]             170             170\n",
      "=======================================================================\n",
      "Total params: 1,913,584\n",
      "Trainable params: 1,913,584\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GPU is available\n",
      "pk: 29.50 %\n",
      "Learning rate: 0.0010000000\n",
      "Epoch: 0............. Loss: 1.9654\n",
      "pk: 40.36 %\n",
      "Learning rate: 0.0010400000\n",
      "Epoch: 1............. Loss: 1.7021\n",
      "pk: 46.15 %\n",
      "Learning rate: 0.0010816000\n",
      "Epoch: 2............. Loss: 1.6227\n",
      "pk: 51.61 %\n",
      "Learning rate: 0.0011248640\n",
      "Epoch: 3............. Loss: 1.5406\n",
      "pk: 55.60 %\n",
      "Learning rate: 0.0011698586\n",
      "Epoch: 4............. Loss: 1.2989\n",
      "pk: 59.29 %\n",
      "Learning rate: 0.0012166529\n",
      "Epoch: 5............. Loss: 1.1808\n",
      "pk: 61.91 %\n",
      "Learning rate: 0.0012653190\n",
      "Epoch: 6............. Loss: 1.1468\n",
      "pk: 64.25 %\n",
      "Learning rate: 0.0013159318\n",
      "Epoch: 7............. Loss: 0.9750\n",
      "pk: 65.32 %\n",
      "Learning rate: 0.0013685691\n",
      "Epoch: 8............. Loss: 1.0980\n",
      "pk: 67.39 %\n",
      "Learning rate: 0.0014233118\n",
      "Epoch: 9............. Loss: 0.9936\n",
      "pk: 68.13 %\n",
      "Learning rate: 0.0014802443\n",
      "Epoch: 10............. Loss: 0.9120\n",
      "pk: 69.16 %\n",
      "Learning rate: 0.0015394541\n",
      "Epoch: 11............. Loss: 0.7168\n",
      "pk: 69.86 %\n",
      "Learning rate: 0.0016010322\n",
      "Epoch: 12............. Loss: 0.9064\n",
      "pk: 70.97 %\n",
      "Learning rate: 0.0016650735\n",
      "Epoch: 13............. Loss: 0.7748\n",
      "pk: 71.81 %\n",
      "Learning rate: 0.0017316764\n",
      "Epoch: 14............. Loss: 0.6981\n",
      "pk: 72.11 %\n",
      "Learning rate: 0.0018009435\n",
      "Epoch: 15............. Loss: 0.7964\n",
      "pk: 72.64 %\n",
      "Learning rate: 0.0018729812\n",
      "Epoch: 16............. Loss: 0.5899\n",
      "pk: 73.22 %\n",
      "Learning rate: 0.0019479005\n",
      "Epoch: 17............. Loss: 0.6366\n",
      "pk: 73.02 %\n",
      "Learning rate: 0.0020258165\n",
      "Epoch: 18............. Loss: 0.7073\n",
      "pk: 70.27 %\n",
      "Learning rate: 0.0021068492\n",
      "Epoch: 19............. Loss: 0.5888\n",
      "pk: 73.77 %\n",
      "Learning rate: 0.0021911231\n",
      "Epoch: 20............. Loss: 0.5210\n",
      "pk: 74.34 %\n",
      "Learning rate: 0.0022787681\n",
      "Epoch: 21............. Loss: 0.8241\n",
      "pk: 73.91 %\n",
      "Learning rate: 0.0023699188\n",
      "Epoch: 22............. Loss: 0.6361\n",
      "pk: 74.17 %\n",
      "Learning rate: 0.0024647155\n",
      "Epoch: 23............. Loss: 0.5693\n"
     ]
    }
   ],
   "source": [
    "# input image size in px (square image)\n",
    "input_size = 32\n",
    "dataset_name = \"cifar\"\n",
    "epoch = 40\n",
    "\n",
    "methods = [\"xavier_uniform\",'xavier_uniform_M_10', 'xavier_uniform_M_2', 'xavier_uniform_M_1', 'xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "for method in methods:\n",
    "    for apt in range(3):\n",
    "        model = TrainModel(dataset=CifarDataset(), method=method, input_size=input_size,\n",
    "                                c_kernels=[5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=epoch)\n",
    "        sse, sse_t, acc, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + dataset_name + method + \"_\" + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + \"_\" + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + dataset_name + method + str(apt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 150\n",
    "dataset_name = \"intel\"\n",
    "methods = ['xavier_uniform_M_10', 'xavier_uniform_M_2', 'xavier_uniform_M_1', 'xavier_uniform_M_14', 'xavier_uniform_M_20']\n",
    "\n",
    "for method in methods:\n",
    "    for apt in range(13, 14, 1):\n",
    "        model = TrainModel(dataset=IntelDataset(), method=method, input_size=input_size,\n",
    "                            c_kernels=[7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[3, 16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128], apt=apt, dataset_name=dataset_name, epoch=200)\n",
    "        sse, sse_t, pk, e = model.training()\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + str(apt) + \".csv\", sse, delimiter=\";\")\n",
    "        np.savetxt(\"./output_data/data_plots/\" + method + str(apt) + \"_t.csv\", sse_t, delimiter=\";\")\n",
    "        with open('./output_data/acc/' + method + str(apt) + '.txt', 'w') as f:\n",
    "            f.write('pk: ' + str(acc) + '\\n')\n",
    "        torch.save(model.cnn_model, \"./output_data/models/\" + method + str(apt))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
