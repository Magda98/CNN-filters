{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import sklearn\n",
    "from WeaponData import WeaponData\n",
    "from cnn import CnnNet\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import adaptive_leraning_rate, weights_init\n",
    "import shap\n",
    "from pytorch_model_summary import summary\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['banknot', 'karta płatnicza', 'nóż', 'pistolet', 'portfel', 'smartphone']\n"
     ]
    }
   ],
   "source": [
    "dataset = WeaponData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 12\n"
     ]
    }
   ],
   "source": [
    "net = CnnNet(100, len(dataset.classes),  c_kernels=[7, 7, 7, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], in_channels=[\n",
    "             3, 16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128], out_channels=[16, 32, 64, 86, 128, 128, 128, 128, 128, 128, 128, 128, 128], padding_flag=True,\n",
    "                maxpool_freq=4,\n",
    "                activation_relu=True,\n",
    "                fc_size=4,)\n",
    "criterion = nn.NLLLoss()\n",
    "net.apply(lambda m: weights_init(m, \"xavier_uniform\"))\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "loss_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    net.cnn = net.cnn.cuda()\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataset, model, criterion):\n",
    "    total = 0.\n",
    "    predicted = 0.\n",
    "    loss_test = 0.\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataset.testloader:\n",
    "            labels = labels.cuda()\n",
    "            data = data.cuda()\n",
    "            out = model(data)\n",
    "            predicted_output = torch.argmax(out, dim=1)\n",
    "\n",
    "            y_true = np.append(y_true, labels.cpu().detach().numpy(), 0)\n",
    "            y_pred = np.append(y_pred, predicted_output.cpu().detach().numpy(), 0)\n",
    "            total += labels.shape[0]\n",
    "            predicted += torch.sum(predicted_output == labels).cpu().item()\n",
    "\n",
    "            loss = criterion(out, labels)\n",
    "            loss_test += loss.cpu().item()\n",
    "    confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    return (predicted/total*100), loss_test, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 49.00 %\n",
      "Learning rate: 0.0001000000\n",
      "Epoch: 0............. Loss: 1.3835\n",
      "acc: 53.15 %\n",
      "Learning rate: 0.0001040000\n",
      "Epoch: 1............. Loss: 1.2892\n",
      "acc: 66.47 %\n",
      "Learning rate: 0.0001081600\n",
      "Epoch: 2............. Loss: 0.7130\n",
      "acc: 70.15 %\n",
      "Learning rate: 0.0001124864\n",
      "Epoch: 3............. Loss: 1.0657\n",
      "acc: 70.51 %\n",
      "Learning rate: 0.0001169859\n",
      "Epoch: 4............. Loss: 0.7035\n",
      "acc: 72.61 %\n",
      "Learning rate: 0.0001216653\n",
      "Epoch: 5............. Loss: 0.6936\n",
      "acc: 72.82 %\n",
      "Learning rate: 0.0001265319\n",
      "Epoch: 6............. Loss: 0.9170\n",
      "acc: 73.29 %\n",
      "Learning rate: 0.0001315932\n",
      "Epoch: 7............. Loss: 0.4689\n",
      "acc: 75.08 %\n",
      "Learning rate: 0.0001368569\n",
      "Epoch: 8............. Loss: 0.5834\n",
      "acc: 76.13 %\n",
      "Learning rate: 0.0001423312\n",
      "Epoch: 9............. Loss: 0.7187\n",
      "acc: 75.81 %\n",
      "Learning rate: 0.0001480244\n",
      "Epoch: 10............. Loss: 0.4318\n",
      "acc: 75.55 %\n",
      "Learning rate: 0.0001539454\n",
      "Epoch: 11............. Loss: 0.5484\n",
      "acc: 74.71 %\n",
      "Learning rate: 0.0001601032\n",
      "Epoch: 12............. Loss: 0.2592\n",
      "acc: 76.86 %\n",
      "Learning rate: 0.0001665074\n",
      "Epoch: 13............. Loss: 0.5162\n",
      "acc: 77.70 %\n",
      "Learning rate: 0.0001731676\n",
      "Epoch: 14............. Loss: 0.1908\n"
     ]
    }
   ],
   "source": [
    "\n",
    "old_loss = 0\n",
    "loss_training = []\n",
    "for e in range(15):\n",
    "    old_param = net.parameters\n",
    "\n",
    "    loss_temp = 0\n",
    "    # pass through all data\n",
    "    for data, exp in dataset.trainloader:\n",
    "        exp = exp.cuda()\n",
    "        # pass data to cuda\n",
    "        data = data.cuda()\n",
    "        # clear gradient from previous epoch\n",
    "        optimizer.zero_grad()\n",
    "        out = net(data)\n",
    "        loss = criterion(out, exp)\n",
    "        loss.backward()\n",
    "        loss_temp += loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_training.append(loss_temp)\n",
    "    acc, loss_test, mat = test(dataset, net, criterion)\n",
    "    net, optimizer = adaptive_leraning_rate(loss_training[-1], optimizer, net, old_param, old_loss)\n",
    "    old_loss = loss_training[-1]\n",
    "    \n",
    "    \n",
    "\n",
    "    # ax= plt.subplot()\n",
    "    # sns.heatmap(mat, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
    "\n",
    "    # ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    # ax.set_title('Confusion Matrix'); \n",
    "    # ax.xaxis.set_ticklabels(['1', '2', '3', '4', '5', '6']); ax.yaxis.set_ticklabels(['1', '2', '3', '4', '5', '6']);\n",
    "    # plt.show()\n",
    "    \n",
    "    temp_lr: float = optimizer.param_groups[0]['lr']\n",
    "    print(\"acc: {:.2f} %\".format(acc))\n",
    "    print(\"Learning rate: {:.10f}\".format(temp_lr))\n",
    "    print(\"Epoch: {}.............\".format(e), end=\" \")\n",
    "    print(\"Loss: {:.4f}\".format(loss))\n",
    "    if acc > 80.0:\n",
    "        break\n",
    "\n",
    "torch.save(net, \"./output_data/models/weapon_dataset\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
