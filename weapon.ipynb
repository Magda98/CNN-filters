{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import sklearn\n",
    "from weapon_data import WeaponData\n",
    "from cnn import CnnNet\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import os\n",
    "import itertools\n",
    "%config InlineBackend.figure_format = 'svg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['billete', 'knife', 'monedero', 'pistol', 'smartphone', 'tarjeta']\n"
     ]
    }
   ],
   "source": [
    "dataset = WeaponData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilość klas: 6\n",
      "wielkość po warstawach conv: 10\n"
     ]
    }
   ],
   "source": [
    "net = CnnNet(64, len(dataset.classes),  c_kernels=[3, 3, 3, 3, 3, 3], in_channels=[3, 16, 32, 64, 86, 128, 128], out_channels=[16, 32, 64, 86, 128, 128])\n",
    "criterion = nn.NLLLoss()\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "loss_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "    net.cnn = net.cnn.cuda()\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_classification(out, d):\n",
    "    \"\"\"\n",
    "        Function calculating valid classification\n",
    "        @ out - netowerk output\n",
    "        @ d - destination value\n",
    "        return: classification correctness in %\n",
    "        \"\"\"\n",
    "    out = out.cpu().detach().numpy()\n",
    "    d = d.cpu().detach().numpy()\n",
    "    temp = abs(d - out)\n",
    "    valid = sum(i < 0.5 for i in temp)\n",
    "    return valid / temp.shape[0] * 100  # type:ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n"
     ]
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, cmap=cm.Blues, show=True):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        title = 'Normalized confusion matrix'\n",
    "    else:\n",
    "        title = 'Confusion matrix'\n",
    "\n",
    "    # Calculate chart area size\n",
    "    leftmargin = 0.5  # inches\n",
    "    rightmargin = 0.5  # inches\n",
    "    categorysize = 0.5  # inches\n",
    "    figwidth = leftmargin + rightmargin + (len(classes) * categorysize)\n",
    "\n",
    "    f = plt.figure(figsize=(figwidth, figwidth))\n",
    "\n",
    "    # Create an axes instance and ajust the subplot size\n",
    "    ax = f.add_subplot(111)\n",
    "    ax.set_aspect(1)\n",
    "    f.subplots_adjust(left=leftmargin/figwidth, right=1-rightmargin/figwidth, top=0.94, bottom=0.1)\n",
    "\n",
    "    res = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.colorbar(res)\n",
    "    ax.set_xticks(range(len(classes)))\n",
    "    ax.set_yticks(range(len(classes)))\n",
    "    ax.set_xticklabels(classes, rotation=45, ha='right')\n",
    "    ax.set_yticklabels(classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "        plt.close(f)\n",
    "    else:\n",
    "        plt.close(f)\n",
    "            \n",
    "def test():\n",
    "    loss_t = 0\n",
    "    pk = []\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataset.testloader:\n",
    "            labels = labels.cuda()\n",
    "            data = data.cuda()\n",
    "            out, _ = net(data)\n",
    "            output = torch.argmax(out.detach(), dim=1)\n",
    "            loss = criterion(out, labels)\n",
    "            loss_t += loss.cpu().item()\n",
    "            y_true = np.append(y_true, labels.cpu().detach().numpy(), 0)\n",
    "            y_pred = np.append(y_pred, output.cpu().detach().numpy(), 0)\n",
    "            pk.append(valid_classification(output, labels))\n",
    "    mtrix = sklearn.metrics.confusion_matrix(y_true, y_pred)\n",
    "    loss_test.append(loss_t)\n",
    "    return (np.average(pk), mtrix)  # type:ignore\n",
    "\n",
    "\n",
    "# sourcery skip: hoist-statement-from-loop\n",
    "loss = 0\n",
    "print(\"start\")\n",
    "for e in range(100):\n",
    "    old_param = net.parameters\n",
    "    # pass through all data\n",
    "    for data, exp in dataset.trainloader:\n",
    "        exp = exp.cuda()\n",
    "        # pass data to cuda\n",
    "        data = data.cuda()\n",
    "        # clear gradient from previous epoch\n",
    "        optimizer.zero_grad()\n",
    "        out, sample = net(data)\n",
    "        loss = criterion(out, exp)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    pk, mat = test()\n",
    "    plot_confusion_matrix(mat, dataset.classes)\n",
    "   \n",
    "    temp_lr: float = optimizer.param_groups[0]['lr']\n",
    "    print(\"pk: {:.2f} %\".format(pk))\n",
    "    print(\"Learning rate: {:.10f}\".format(temp_lr))\n",
    "    print('Epoch: {}.............'.format(e), end=' ')\n",
    "    print(\"Loss: {:.4f}\".format(loss))\n",
    "    \n",
    "torch.save(net, \"models/weapon\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "483af022b5ec7d24700bcdf0e25d1e2b25f3a954a5b2083e220785423700196e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
